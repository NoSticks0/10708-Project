{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This needs to be here because by default Jupyter only adds the pwd to sys.path\n",
    "import os, sys\n",
    "if os.path.abspath('..') not in sys.path: sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pysrc.constants import datapath, N_ITEMS, N_USERS\n",
    "from pysrc.constants import cachepath, datapath, chartpath\n",
    "import torch\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {}\n",
    "test_dict = {}\n",
    "\n",
    "with open(datapath(\"train.txt\")) as file:\n",
    "    for line in file:\n",
    "        (user_id, items) = line.split(maxsplit=1)\n",
    "        train_dict[user_id] = items\n",
    "\n",
    "with open(datapath(\"test.txt\")) as file:\n",
    "    for line in file:\n",
    "        split = line.split(maxsplit=1)\n",
    "        if (len(split) > 1):\n",
    "            (user_id, items) = split\n",
    "            test_dict[user_id] = items\n",
    "        else:\n",
    "            test_dict[split[0]] = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "test = []\n",
    "for key in train_dict:\n",
    "    train.append([int(n) for n in train_dict[key].replace('\\n', '').split(' ')])\n",
    "\n",
    "for key in test_dict:\n",
    "    if len(test_dict[key]) == 0:\n",
    "        test.append([])\n",
    "    else:\n",
    "        test.append([int(n) for n in test_dict[key].replace('\\n', '').split(' ')])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7305, 0.1318, 0.8023, 0.2511, 0.6896],\n",
       "        [0.6473, 0.3216, 0.4908, 0.5457, 0.3819],\n",
       "        [0.9673, 0.0999, 0.8944, 0.4907, 0.7014],\n",
       "        [0.9334, 0.0156, 0.7859, 0.0726, 0.9799],\n",
       "        [0.3108, 0.5575, 0.5187, 0.4486, 0.9182],\n",
       "        [0.0295, 0.4234, 0.4989, 0.7567, 0.9021],\n",
       "        [0.2313, 0.0659, 0.7758, 0.5792, 0.9325],\n",
       "        [0.6996, 0.4364, 0.6904, 0.0649, 0.9177],\n",
       "        [0.1747, 0.2700, 0.5366, 0.5250, 0.4218],\n",
       "        [0.1496, 0.5449, 0.2079, 0.5094, 0.9219]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((10,5))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def log_likelihood_loss(y, yhat):\n",
    "    return -torch.mean(torch.sum(torch.log(yhat+1e-6) * y, axis = 1))\n",
    "\n",
    "def likelihood_loss(y, yhat):\n",
    "    return -torch.mean(torch.sum(yhat * y, axis = 1))\n",
    "\n",
    "class VanillaVAE(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 latent_dim: int,\n",
    "                 hidden_dims = None,\n",
    "                 kl_weight = .2\n",
    "                 ):\n",
    "        super(VanillaVAE, self).__init__()\n",
    "        \n",
    "        self.kl_weight = kl_weight\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        modules = []\n",
    "        \n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [512, 128]\n",
    "            \n",
    "        self.hidden_dims = hidden_dims\n",
    "            \n",
    "        modules.append(nn.Linear(input_dim, hidden_dims[0]))\n",
    "        modules.append(nn.BatchNorm1d(hidden_dims[0]))\n",
    "        modules.append(nn.LeakyReLU())\n",
    "        \n",
    "        # Build Encoder\n",
    "        for i in range(len(hidden_dims)-1):\n",
    "            modules.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n",
    "            modules.append(nn.BatchNorm1d(hidden_dims[i+1]))\n",
    "            modules.append(nn.LeakyReLU())\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "        self.fc_mu = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "        self.fc_var = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "\n",
    "        # Build Decoder\n",
    "        modules = []\n",
    "\n",
    "        self.decoder_input = nn.Linear(latent_dim, hidden_dims[-1])\n",
    "\n",
    "        hidden_dims.reverse()\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n",
    "            modules.append(nn.BatchNorm1d(hidden_dims[i+1]))\n",
    "            modules.append(nn.LeakyReLU())\n",
    "\n",
    "\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "        self.final_layer = nn.Sequential(nn.Linear(hidden_dims[-1], input_dim),\n",
    "                                         nn.Sigmoid()\n",
    "                                        )\n",
    "        \n",
    "\n",
    "    def encode(self, input: Tensor):\n",
    "        \"\"\"\n",
    "        Encodes the input by passing through the encoder network\n",
    "        and returns the latent codes.\n",
    "        :param input: (Tensor) Input tensor to encoder [N x C x H x W]\n",
    "        :return: (Tensor) List of latent codes\n",
    "        \"\"\"\n",
    "        result = self.encoder(input)\n",
    "        result = torch.flatten(result, start_dim=1)\n",
    "\n",
    "        # Split the result into mu and var components\n",
    "        # of the latent Gaussian distribution\n",
    "        mu = self.fc_mu(result)\n",
    "        log_var = self.fc_var(result)\n",
    "\n",
    "        return [mu, log_var]\n",
    "\n",
    "    def decode(self, z: Tensor):\n",
    "        \"\"\"\n",
    "        Maps the given latent codes\n",
    "        onto the image space.\n",
    "        :param z: (Tensor) [B x D]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "        result = self.decoder_input(z)\n",
    "        result = result.view(-1, self.hidden_dims[0])\n",
    "        result = self.decoder(result)\n",
    "        result = self.final_layer(result)\n",
    "        result = F.normalize(result, p=1)\n",
    "        return result\n",
    "\n",
    "    def reparameterize(self, mu: Tensor, logvar: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Reparameterization trick to sample from N(mu, var) from\n",
    "        N(0,1).\n",
    "        :param mu: (Tensor) Mean of the latent Gaussian [B x D]\n",
    "        :param logvar: (Tensor) Standard deviation of the latent Gaussian [B x D]\n",
    "        :return: (Tensor) [B x D]\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "\n",
    "    def forward(self, x: Tensor, **kwargs):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        return  [F.normalize(self.decode(z), 1, dim=1), x, mu, log_var]\n",
    "\n",
    "    def loss_function(self, recons, x, mu, log_var) -> dict:\n",
    "        \"\"\"\n",
    "        Computes the VAE loss function.\n",
    "        KL(N(\\mu, \\sigma), N(0, 1)) = \\log \\frac{1}{\\sigma} + \\frac{\\sigma^2 + \\mu^2}{2} - \\frac{1}{2}\n",
    "        :param args:\n",
    "        :param kwargs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        kld_weight = self.kl_weight\n",
    "        recons_loss = log_likelihood_loss(x, recons)\n",
    "\n",
    "        kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1), dim = 0)\n",
    "\n",
    "        loss = recons_loss + kld_weight * kld_loss\n",
    "        return {'loss': loss, 'Reconstruction_Loss':recons_loss.detach(), 'KLD':-kld_loss.detach()}\n",
    "\n",
    "    def sample(self,\n",
    "               num_samples:int,\n",
    "               current_device: int, **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the latent space and return the corresponding\n",
    "        image space map.\n",
    "        :param num_samples: (Int) Number of samples\n",
    "        :param current_device: (Int) Device to run the model\n",
    "        :return: (Tensor)\n",
    "        \"\"\"\n",
    "        z = torch.randn(num_samples,\n",
    "                        self.latent_dim)\n",
    "\n",
    "        z = z.to(current_device)\n",
    "\n",
    "        samples = self.decode(z)\n",
    "        return samples\n",
    "\n",
    "    def generate(self, x: Tensor, **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Given an input image x, returns the reconstructed image\n",
    "        :param x: (Tensor) [B x C x H x W]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "\n",
    "        return self.forward(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_dim = 91599\n",
    "np.random.seed(0)\n",
    "test_ids = np.random.choice(np.array(list(train_dict.keys())).astype(int), int(.2*len(train_dict.keys())), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsify_uniform(data, p_relative = .1):\n",
    "    current_sparse = None\n",
    "    batch_size = 1000\n",
    "    X = []\n",
    "    for row in data:\n",
    "        X.append(torch.zeros(item_dim).bool())\n",
    "        for item in row:\n",
    "            if np.random.random() > p_relative:\n",
    "                X[-1][item] = 1\n",
    "        X[-1] = X[-1]\n",
    "    X = torch.stack(X)\n",
    "    return X\n",
    "    \n",
    "def sparsify_items(data, m, sigma):\n",
    "    return\n",
    "\n",
    "def sparsify_users(data, m, sigma):\n",
    "    return\n",
    "\n",
    "def list_batch_to_ohe(data):\n",
    "    return sparsify_uniform(data, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train, val, n_epochs = 100):\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "        total_loading_time = 0\n",
    "        for batch_X, batch_Y in train:\n",
    "            batch_X = batch_X.float().cuda()\n",
    "            batch_Y = batch_Y.float().cuda()\n",
    "            recons, x, mu, log_var = model.forward(batch_X)\n",
    "            train_loss = model.loss_function(recons, batch_Y, mu, log_var)['loss']\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Done Epoch {epoch}\")\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                total_train_loss = 0\n",
    "                r_train_loss = 0\n",
    "                kl_train_loss = 0\n",
    "                train_batches = 0\n",
    "                for batch_X, batch_Y in train:\n",
    "                    batch_X = batch_X.float().cuda()\n",
    "                    batch_Y = batch_Y.float().cuda()\n",
    "                    recons, x, mu, log_var = model.forward(batch_X)\n",
    "                    loss = model.loss_function(recons, batch_Y, mu, log_var)\n",
    "                    total_train_loss += loss['loss']\n",
    "                    r_train_loss += loss['Reconstruction_Loss']\n",
    "                    kl_train_loss += loss['KLD']\n",
    "                    train_batches += 1\n",
    "\n",
    "                total_train_loss /= train_batches\n",
    "                r_train_loss /= train_batches\n",
    "                kl_train_loss /= train_batches\n",
    "\n",
    "                total_loss = 0\n",
    "                r_loss = 0\n",
    "                kl_loss = 0\n",
    "                batches = 0\n",
    "                for batch_X, batch_Y in val:\n",
    "                    batch_X = batch_X.float().cuda()\n",
    "                    batch_Y = batch_Y.float().cuda()\n",
    "                    recons, x, mu, log_var = model.forward(batch_X)\n",
    "                    loss = model.loss_function(recons, batch_Y, mu, log_var)\n",
    "                    total_loss += loss['loss']\n",
    "                    r_loss += loss['Reconstruction_Loss']\n",
    "                    kl_loss += loss['KLD']\n",
    "                    batches += 1\n",
    "\n",
    "                total_loss /= batches\n",
    "                r_loss /= batches\n",
    "                kl_loss /= batches\n",
    "            print(\"Train Loss\", total_train_loss)\n",
    "            print(\"Val Loss\", total_loss)\n",
    "            \n",
    "def train_model_old(model, train, val, n_epochs = 100):\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Start Epoch {epoch}\")\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "        total_loading_time = 0\n",
    "        for batch_X, batch_Y in train:\n",
    "            batch_X = batch_X.float().cuda()\n",
    "            recons, x, mu, log_var = model.forward(batch_X)\n",
    "            train_loss = model.loss_function(recons, batch_X, mu, log_var)['loss']\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        '''\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            total_train_loss = 0\n",
    "            r_train_loss = 0\n",
    "            kl_train_loss = 0\n",
    "            train_batches = 0\n",
    "            for batch_X, batch_Y in train:\n",
    "                batch_X = batch_X.float().cuda()\n",
    "                recons, x, mu, log_var = model.forward(batch_X)\n",
    "                loss = model.loss_function(recons, batch_X, mu, log_var)\n",
    "                total_train_loss += loss['loss']\n",
    "                r_train_loss += loss['Reconstruction_Loss']\n",
    "                kl_train_loss += loss['KLD']\n",
    "                train_batches += 1\n",
    "\n",
    "            total_train_loss /= train_batches\n",
    "            r_train_loss /= train_batches\n",
    "            kl_train_loss /= train_batches\n",
    "\n",
    "            total_loss = 0\n",
    "            r_loss = 0\n",
    "            kl_loss = 0\n",
    "            batches = 0\n",
    "            for batch_X, batch_Y in val:\n",
    "                batch_X = batch_X.float().cuda()\n",
    "                recons, x, mu, log_var = model.forward(batch_X)\n",
    "                loss = model.loss_function(recons, batch_X, mu, log_var)\n",
    "                total_loss += loss['loss']\n",
    "                r_loss += loss['Reconstruction_Loss']\n",
    "                kl_loss += loss['KLD']\n",
    "                batches += 1\n",
    "\n",
    "            total_loss /= batches\n",
    "            r_loss /= batches\n",
    "            kl_loss /= batches\n",
    "        '''\n",
    "def top_k_recall(X_in, X_out, X_target, k = 20, mask_in = True):\n",
    "    if mask_in:\n",
    "        mask = X_in == False\n",
    "        X_out = X_out * mask\n",
    "    topk = torch.topk(X_out, k)\n",
    "    n = 0\n",
    "    total_recall = 0\n",
    "    for i in range(len(X_in)):\n",
    "        if int(X_target[i].sum()) == 0:\n",
    "            continue\n",
    "        selected = topk.indices[i]\n",
    "        total_recall += X_target[i][selected].sum() / X_target[i].sum()\n",
    "        n += 1\n",
    "    \n",
    "    return total_recall / n\n",
    "\n",
    "def n_recall(X_in, X_out, X_target, mask_in = True):\n",
    "    if mask_in:\n",
    "        mask = X_in == False\n",
    "        X_out = X_out * mask\n",
    "        X_target = X_target * mask\n",
    "    topk = torch.topk(X_out, int(X_target.sum(axis=1).max()), sorted=True)\n",
    "    n = 0\n",
    "    total_recall = 0\n",
    "    for i in range(len(X_in)):\n",
    "        if int(X_target[i].sum()) == 0:\n",
    "            continue\n",
    "        selected = topk.indices[i]\n",
    "        total_recall += X_target[i][selected[:int(X_target[i].sum())]].sum() / int(X_target[i].sum())\n",
    "        n += 1\n",
    "    #print(total_recall,n)\n",
    "    #print(len(X_in))\n",
    "    return total_recall / len(X_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This needs to be here because by default Jupyter only adds the pwd to sys.path\n",
    "import os, sys\n",
    "if os.path.abspath('..') not in sys.path: sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import scipy\n",
    "import pickle \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from pysrc.constants import datapath#, N_ITEMS, N_USERS\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_jaccard_sparse(csr):\n",
    "    \"\"\"Computes the Jaccard distance between the rows of `csr`,\n",
    "    smaller than the cut-off distance `epsilon`.\n",
    "    \"\"\"\n",
    "    csr = csr_matrix(csr).astype(bool).astype(int)\n",
    "\n",
    "    csr_rownnz = csr.getnnz(axis=1)\n",
    "    intrsct = csr.dot(csr.T)\n",
    "\n",
    "    nnz_i = np.repeat(csr_rownnz, intrsct.getnnz(axis=1))\n",
    "    unions = nnz_i + csr_rownnz[intrsct.indices] - intrsct.data\n",
    "    dists = intrsct.data / unions\n",
    "\n",
    "    out = csr_matrix((dists, intrsct.indices, intrsct.indptr), intrsct.shape)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsify_sparse_uniform(sparse_X, p_relative = .1):\n",
    "    X = []\n",
    "    for i in range(sparse_train_data.shape[0]):\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "        X.append(torch.zeros(item_dim).bool())\n",
    "        row = sparse_X[i].coalesce().indices()[0]\n",
    "        X[-1][row] = 1\n",
    "    X = torch.stack(X)\n",
    "    return X\n",
    "    \n",
    "def sparse_to_ohe(data):\n",
    "    return sparsify_sparse_uniform(data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "def log_likelihood_loss(y, yhat):\n",
    "    return -torch.mean(torch.sum(torch.log(yhat+1e-6) * y, axis = 1))\n",
    "\n",
    "def likelihood_loss(y, yhat):\n",
    "    return -torch.mean(torch.sum(yhat * y, axis = 1))\n",
    "\n",
    "class GraphVAE(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 latent_dim: int,\n",
    "                 hidden_dims = None,\n",
    "                 kl_weight = .2,\n",
    "                 sim = None\n",
    "                 ):\n",
    "        super(GraphVAE, self).__init__()\n",
    "        \n",
    "        self.kl_weight = kl_weight\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.embeddings = torch.zeros(N_USERS, self.latent_dim).cuda()\n",
    "        \n",
    "        coo = sim.tocoo()\n",
    "        \n",
    "        values = coo.data\n",
    "        indices = np.vstack((coo.row, coo.col))\n",
    "\n",
    "        i = torch.LongTensor(indices)\n",
    "        v = torch.FloatTensor(values)\n",
    "        shape = coo.shape\n",
    "\n",
    "        self.neighbors = torch.sparse.FloatTensor(i, v, torch.Size(shape)).cuda()\n",
    "\n",
    "        \n",
    "        modules = []\n",
    "        \n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [512, 128]\n",
    "            \n",
    "        self.hidden_dims = hidden_dims\n",
    "            \n",
    "        modules.append(nn.Linear(input_dim, hidden_dims[0]))\n",
    "        modules.append(nn.BatchNorm1d(hidden_dims[0]))\n",
    "        modules.append(nn.LeakyReLU())\n",
    "        \n",
    "        # Build Encoder\n",
    "        for i in range(len(hidden_dims)-1):\n",
    "            modules.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n",
    "            modules.append(nn.BatchNorm1d(hidden_dims[i+1]))\n",
    "            modules.append(nn.LeakyReLU())\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "        self.fc_mu = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "        self.fc_var = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "\n",
    "        # Build Decoder\n",
    "        modules = []\n",
    "\n",
    "        self.decoder_input = nn.Linear(2 * latent_dim, hidden_dims[-1])\n",
    "\n",
    "        hidden_dims.reverse()\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n",
    "            modules.append(nn.BatchNorm1d(hidden_dims[i+1]))\n",
    "            modules.append(nn.LeakyReLU())\n",
    "\n",
    "\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "        self.final_layer = nn.Sequential(nn.Linear(hidden_dims[-1], input_dim),\n",
    "                                         nn.Sigmoid()\n",
    "                                        )\n",
    "        \n",
    "\n",
    "    def encode(self, input: Tensor):\n",
    "        \"\"\"\n",
    "        Encodes the input by passing through the encoder network\n",
    "        and returns the latent codes.\n",
    "        :param input: (Tensor) Input tensor to encoder [N x C x H x W]\n",
    "        :return: (Tensor) List of latent codes\n",
    "        \"\"\"\n",
    "        result = self.encoder(input)\n",
    "        result = torch.flatten(result, start_dim=1)\n",
    "        # Split the result into mu and var components\n",
    "        # of the latent Gaussian distribution\n",
    "        mu = self.fc_mu(result)\n",
    "        log_var = self.fc_var(result)\n",
    "\n",
    "        return [mu, log_var]\n",
    "\n",
    "    def decode(self, z: Tensor):\n",
    "        \"\"\"\n",
    "        Maps the given latent codes\n",
    "        onto the image space.\n",
    "        :param z: (Tensor) [B x D]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "        result = self.decoder_input(z)\n",
    "        result = result.view(-1, self.hidden_dims[0])\n",
    "        result = self.decoder(result)\n",
    "        result = self.final_layer(result)\n",
    "        result = F.normalize(result, p=1)\n",
    "        return result\n",
    "\n",
    "    def reparameterize(self, mu: Tensor, logvar: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Reparameterization trick to sample from N(mu, var) from\n",
    "        N(0,1).\n",
    "        :param mu: (Tensor) Mean of the latent Gaussian [B x D]\n",
    "        :param logvar: (Tensor) Standard deviation of the latent Gaussian [B x D]\n",
    "        :return: (Tensor) [B x D]\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "\n",
    "    def forward(self, x: Tensor, uids):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        self.embeddings[uids] = z.detach()\n",
    "        neighbors = torch.stack([self.neighbors[uid].to_dense() for uid in uids])\n",
    "        for i in range(len(uids)):\n",
    "            neighbors[i, uids[i]] = 0\n",
    "            \n",
    "        neighbors[:,test_ids] = 0\n",
    "        \n",
    "        neighbor_embeds = ((neighbors @ self.embeddings).T / (torch.sum(neighbors, axis = 1) + 1e-5)).T\n",
    "        \n",
    "        z = torch.cat([z, neighbor_embeds], axis=1)\n",
    "        \n",
    "        return  [F.normalize(self.decode(z), 1, dim=1), x, mu, log_var]\n",
    "    \n",
    "        \n",
    "    def set_embeddings(self, x, uids):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        self.embeddings[uids] = z.detach()\n",
    "\n",
    "    def loss_function(self, recons, x, mu, log_var) -> dict:\n",
    "        \"\"\"\n",
    "        Computes the VAE loss function.\n",
    "        KL(N(\\mu, \\sigma), N(0, 1)) = \\log \\frac{1}{\\sigma} + \\frac{\\sigma^2 + \\mu^2}{2} - \\frac{1}{2}\n",
    "        :param args:\n",
    "        :param kwargs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        kld_weight = self.kl_weight\n",
    "        recons_loss = log_likelihood_loss(x, recons)\n",
    "\n",
    "        kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1), dim = 0)\n",
    "\n",
    "        loss = recons_loss + kld_weight * kld_loss\n",
    "        return {'loss': loss, 'Reconstruction_Loss':recons_loss.detach(), 'KLD':-kld_loss.detach()}\n",
    "\n",
    "    def sample(self,\n",
    "               num_samples:int,\n",
    "               current_device: int, **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the latent space and return the corresponding\n",
    "        image space map.\n",
    "        :param num_samples: (Int) Number of samples\n",
    "        :param current_device: (Int) Device to run the model\n",
    "        :return: (Tensor)\n",
    "        \"\"\"\n",
    "        z = torch.randn(num_samples,\n",
    "                        self.latent_dim)\n",
    "\n",
    "        z = z.to(current_device)\n",
    "\n",
    "        samples = self.decode(z)\n",
    "        return samples\n",
    "\n",
    "    def generate(self, x: Tensor, **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Given an input image x, returns the reconstructed image\n",
    "        :param x: (Tensor) [B x C x H x W]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "\n",
    "        return self.forward(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_graph_model(model, train, val, n_epochs = 100):\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "    \n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "        total_loading_time = 0\n",
    "        for batch_X, batch_Y, batch_ind in train:\n",
    "            batch_X = batch_X.float().cuda()\n",
    "            batch_Y = batch_Y.float().cuda()\n",
    "            recons, x, mu, log_var = model.forward(batch_X, batch_ind)\n",
    "            train_loss = model.loss_function(recons, batch_Y, mu, log_var)['loss']\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Done Epoch {epoch}\")\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                total_train_loss = 0\n",
    "                r_train_loss = 0\n",
    "                kl_train_loss = 0\n",
    "                train_batches = 0\n",
    "                for batch_X, batch_Y, batch_ind in train:\n",
    "                    batch_X = batch_X.float().cuda()\n",
    "                    batch_Y = batch_Y.float().cuda()\n",
    "                    recons, x, mu, log_var = model.forward(batch_X, batch_ind)\n",
    "                    loss = model.loss_function(recons, batch_Y, mu, log_var)\n",
    "                    total_train_loss += loss['loss']\n",
    "                    r_train_loss += loss['Reconstruction_Loss']\n",
    "                    kl_train_loss += loss['KLD']\n",
    "                    train_batches += 1\n",
    "\n",
    "                total_train_loss /= train_batches\n",
    "                r_train_loss /= train_batches\n",
    "                kl_train_loss /= train_batches\n",
    "\n",
    "                total_loss = 0\n",
    "                r_loss = 0\n",
    "                kl_loss = 0\n",
    "                batches = 0\n",
    "                for batch_X, batch_Y, batch_ind in val:\n",
    "                    batch_X = batch_X.float().cuda()\n",
    "                    batch_Y = batch_Y.float().cuda()\n",
    "                    recons, x, mu, log_var = model.forward(batch_X, batch_ind)\n",
    "                    loss = model.loss_function(recons, batch_Y, mu, log_var)\n",
    "                    total_loss += loss['loss']\n",
    "                    r_loss += loss['Reconstruction_Loss']\n",
    "                    kl_loss += loss['KLD']\n",
    "                    batches += 1\n",
    "\n",
    "                total_loss /= batches\n",
    "                r_loss /= batches\n",
    "                kl_loss /= batches\n",
    "                \n",
    "            print(\"Train Loss\", total_train_loss)\n",
    "            print(\"Val Loss\", total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_base(train_in_tensor, train_out_tensor, val_in_tensor, val_out_tensor, test_in_tensor, test_out_tensor):\n",
    "    train_dataset = TensorDataset(train_in_tensor, train_in_tensor + train_out_tensor)\n",
    "    val_dataset = TensorDataset(val_in_tensor, val_in_tensor + val_out_tensor)\n",
    "    test_dataset = TensorDataset(test_in_tensor, test_in_tensor + test_out_tensor)\n",
    "    # Create a data loader from the dataset\n",
    "    # Type of sampling and batch size are specified at this step\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=256, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=True)\n",
    "    \n",
    "    lr = 1e-3\n",
    "    model = VanillaVAE(input_dim = item_dim, latent_dim = 256, hidden_dims = [512, 256], kl_weight = 1).cuda()\n",
    "    \n",
    "    train_model(model, train_dataloader, val_dataloader, n_epochs = 30)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_n_recall_train = 0\n",
    "        total_n_train = 0\n",
    "        for batch_X, batch_Y in train_dataloader:\n",
    "            batch_out = model.forward(batch_X.float().cuda())[0].detach().cpu()\n",
    "            n_recall_batch = n_recall(batch_X, batch_out, batch_X, False)\n",
    "            total_n_recall_train += n_recall_batch * len(batch_X)\n",
    "            total_n_train += len(batch_X)\n",
    "        print(\"Train recons recall:\", total_n_recall_train / total_n_train)\n",
    "        train_recons_recall = total_n_recall_train / total_n_train\n",
    "        \n",
    "        total_n_recall_out = 0\n",
    "        total_n_out = 0\n",
    "        for batch_X, batch_Y in train_dataloader:\n",
    "            batch_out = model.forward(batch_X.float().cuda())[0].detach().cpu()\n",
    "            n_recall_batch = n_recall(batch_X, batch_out, batch_Y, True)\n",
    "            total_n_recall_out += n_recall_batch * len(batch_X)\n",
    "            total_n_out += len(batch_X)\n",
    "        print(\"Train pred recall:\", total_n_recall_out / total_n_out)\n",
    "        train_out_recall = total_n_recall_out / total_n_out\n",
    "        \n",
    "        total_n_recall_recons = 0\n",
    "        total_n_recons = 0\n",
    "        for batch_X, batch_Y in test_dataloader:\n",
    "            batch_out = model.forward(batch_X.float().cuda())[0].detach().cpu()\n",
    "            n_recall_batch = n_recall(batch_X, batch_out, batch_X, False)\n",
    "            total_n_recall_recons += n_recall_batch * len(batch_X)\n",
    "            total_n_recons += len(batch_X)\n",
    "        print(\"Test recons recall:\", total_n_recall_recons / total_n_recons)\n",
    "        test_recons_recall = total_n_recall_recons / total_n_recons\n",
    "        \n",
    "        total_n_recall_out = 0\n",
    "        total_n_out = 0\n",
    "        for batch_X, batch_Y in test_dataloader:\n",
    "            batch_out = model.forward(batch_X.float().cuda())[0].detach().cpu()\n",
    "            n_recall_batch = n_recall(batch_X, batch_out, batch_Y, True)\n",
    "            total_n_recall_out += n_recall_batch * len(batch_X)\n",
    "            total_n_out += len(batch_X)\n",
    "        print(\"Test outsample recall:\", total_n_recall_out / total_n_out)\n",
    "        test_outsample_recall = total_n_recall_out / total_n_out\n",
    "    return model, {\"train_recons\": train_recons_recall, \"train_out\": train_out_recall, \"test_recons\": test_recons_recall, \"test_out\": test_outsample_recall}\n",
    "\n",
    "def train_and_eval_graph(sim, train_in_tensor, train_out_tensor, train_uids, val_in_tensor, val_out_tensor, val_uids, test_in_tensor, test_out_tensor, test_uids):\n",
    "    train_dataset = TensorDataset(train_in_tensor, train_in_tensor + train_out_tensor, train_uids)\n",
    "    val_dataset = TensorDataset(val_in_tensor, val_in_tensor + val_out_tensor, val_uids)\n",
    "    test_dataset = TensorDataset(test_in_tensor, test_in_tensor + test_out_tensor, test_uids)\n",
    "    # Create a data loader from the dataset\n",
    "    # Type of sampling and batch size are specified at this step\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=256, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=True)\n",
    "    lr = 2e-3\n",
    "    model = GraphVAE(input_dim = item_dim, latent_dim = 256, hidden_dims = [512, 256], kl_weight = 1, sim = sim).cuda()\n",
    "    \n",
    "    train_graph_model(model, train_dataloader, val_dataloader, n_epochs = 30)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_Y, batch_ind in train_dataloader:\n",
    "            model.set_embeddings(batch_X.float().cuda(), batch_ind)\n",
    "        for batch_X, batch_Y, batch_ind in val_dataloader:\n",
    "            model.set_embeddings(batch_X.float().cuda(), batch_ind)\n",
    "        for batch_X, batch_Y, batch_ind in test_dataloader:\n",
    "            model.set_embeddings(batch_X.float().cuda(), batch_ind)\n",
    "\n",
    "        total_n_recall_recons = 0\n",
    "        total_n_recons = 0\n",
    "        for batch_X, batch_Y, batch_ind in train_dataloader:\n",
    "            batch_out = model.forward(batch_X.float().cuda(), batch_ind)[0].detach().cpu()\n",
    "            n_recall_batch = n_recall(batch_X, batch_out, batch_X, False)\n",
    "            total_n_recall_recons += n_recall_batch * len(batch_ind)\n",
    "            total_n_recons += len(batch_ind)\n",
    "        print(\"Train recons recall:\", total_n_recall_recons / total_n_recons)\n",
    "        test_recons_recall = total_n_recall_recons / total_n_recons\n",
    "\n",
    "\n",
    "        total_n_recall_out = 0\n",
    "        total_n_out = 0\n",
    "        for batch_X, batch_Y, batch_ind in train_dataloader:\n",
    "            batch_out = model.forward(batch_X.float().cuda(), batch_ind)[0].detach().cpu()\n",
    "            n_recall_batch = n_recall(batch_X, batch_out, batch_Y, True)\n",
    "            total_n_recall_out += n_recall_batch * len(batch_X)\n",
    "            total_n_out += len(batch_X)\n",
    "        print(\"Train outsample recall:\", total_n_recall_out / total_n_out)\n",
    "        test_outsample_recall = total_n_recall_out / total_n_out\n",
    "\n",
    "        total_n_recall_recons = 0\n",
    "        total_n_recons = 0\n",
    "        for batch_X, batch_Y, batch_ind in test_dataloader:\n",
    "            batch_out = model.forward(batch_X.float().cuda(), batch_ind)[0].detach().cpu()\n",
    "            n_recall_batch = n_recall(batch_X, batch_out, batch_X, False)\n",
    "            total_n_recall_recons += n_recall_batch * len(batch_X)\n",
    "            total_n_recons += len(batch_X)\n",
    "        print(\"Test recons recall:\", total_n_recall_recons / total_n_recons)\n",
    "        test_recons_recall = total_n_recall_recons / total_n_recons\n",
    "\n",
    "\n",
    "        total_n_recall_out = 0\n",
    "        total_n_out = 0\n",
    "        for batch_X, batch_Y, batch_ind in test_dataloader:\n",
    "            batch_out = model.forward(batch_X.float().cuda(), batch_ind)[0].detach().cpu()\n",
    "            n_recall_batch = n_recall(batch_X, batch_out, batch_Y, True)\n",
    "            total_n_recall_out += n_recall_batch * len(batch_ind)\n",
    "            total_n_out += len(batch_ind)\n",
    "        print(\"Test outsample recall:\", total_n_recall_out / total_n_out)\n",
    "        test_outsample_recall = total_n_recall_out / total_n_out\n",
    "    return model, {\"train_recons\": train_recons_recall, \"train_out\": train_out_recall, \"test_recons\": test_recons_recall, \"test_out\": test_outsample_recall}\n",
    "\n",
    "def compare_on_data(train_path, test_path):\n",
    "    sparse_train_data = torch.load(train_path)\n",
    "    sparse_test_data = pickle.load(open(test_path, \"rb\"))\n",
    "    sim = pairwise_jaccard_sparse(sparse_train_data.to_dense())\n",
    "    for i in range(sim.shape[0]):\n",
    "        sim[i,i] = 0\n",
    "    dev_df = sparse_train_data.bool().to_dense()\n",
    "    test_df = list_batch_to_ohe(pd.Series(sparse_test_data))\n",
    "    test_mask = torch.zeros(dev_df.shape[0])\n",
    "    test_mask[test_ids[test_ids < dev_df.shape[0]]] = 1\n",
    "    \n",
    "    dev_in = dev_df[test_mask == 0]\n",
    "    dev_out = test_df[test_mask == 0]\n",
    "    test_in_tensor = dev_df[test_mask == 1]\n",
    "    test_out_tensor = test_df[test_mask == 1]\n",
    "\n",
    "    train_uids = (1-test_mask).nonzero().reshape(-1)[:int(.7*len(dev_in))]\n",
    "    val_uids = (1-test_mask).nonzero().reshape(-1)[int(.7*len(dev_in)):]\n",
    "    test_uids = test_mask.nonzero().reshape(-1)\n",
    "\n",
    "    train_in_tensor = dev_in[:int(.7*len(dev_in))]\n",
    "    val_in_tensor = dev_in[int(.7*len(dev_in)):]\n",
    "\n",
    "    train_out_tensor = dev_out[:int(.7*len(dev_in))]\n",
    "    val_out_tensor = dev_out[int(.7*len(dev_in)):]\n",
    "\n",
    "    graph_model, graph_results = train_and_eval_graph(sim, train_in_tensor, train_out_tensor, train_uids, val_in_tensor, val_out_tensor, val_uids, test_in_tensor, test_out_tensor, test_uids)\n",
    "    \n",
    "    base_model, base_results = train_and_eval_base(train_in_tensor, train_out_tensor, val_in_tensor, val_out_tensor, test_in_tensor, test_out_tensor)\n",
    "    \n",
    "    return base_model, base_results, graph_model, graph_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Epoch 0\n",
      "Train Loss tensor(667.3203, device='cuda:0')\n",
      "Val Loss tensor(493.6860, device='cuda:0')\n",
      "Done Epoch 10\n",
      "Train Loss tensor(541.6763, device='cuda:0')\n",
      "Val Loss tensor(458.1747, device='cuda:0')\n",
      "Done Epoch 20\n",
      "Train Loss tensor(514.6292, device='cuda:0')\n",
      "Val Loss tensor(442.8649, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\nick\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_19088\\630800855.py\", line 1, in <module>\n",
      "    compare_on_data(datapath(f\"train/uniform/uniform100_data.pt\"), datapath(f\"test/uniform/uniform100_test_indices.pickle\"))\n",
      "  File \"C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_19088\\845619189.py\", line 151, in compare_on_data\n",
      "    graph_model, graph_results = train_and_eval_graph(sim, train_in_tensor, train_out_tensor, train_uids, val_in_tensor, val_out_tensor, val_uids, test_in_tensor, test_out_tensor, test_uids)\n",
      "  File \"C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_19088\\845619189.py\", line 71, in train_and_eval_graph\n",
      "    train_graph_model(model, train_dataloader, val_dataloader, n_epochs = 30)\n",
      "  File \"C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_19088\\3840471047.py\", line 15, in train_graph_model\n",
      "    recons, x, mu, log_var = model.forward(batch_X, batch_ind)\n",
      "  File \"C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_19088\\2008905878.py\", line 129, in forward\n",
      "    neighbors = torch.stack([self.neighbors[uid].to_dense() for uid in uids])\n",
      "  File \"C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_19088\\2008905878.py\", line 129, in <listcomp>\n",
      "    neighbors = torch.stack([self.neighbors[uid].to_dense() for uid in uids])\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\nick\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\nick\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"c:\\users\\nick\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\users\\nick\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"c:\\users\\nick\\appdata\\local\\programs\\python\\python37\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"c:\\users\\nick\\appdata\\local\\programs\\python\\python37\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"c:\\users\\nick\\appdata\\local\\programs\\python\\python37\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"c:\\users\\nick\\appdata\\local\\programs\\python\\python37\\lib\\inspect.py\", line 732, in getmodule\n",
      "    for modname, module in sys.modules.copy().items():\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19088\\630800855.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcompare_on_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"train/uniform/uniform100_data.pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatapath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"test/uniform/uniform100_test_indices.pickle\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19088\\845619189.py\u001b[0m in \u001b[0;36mcompare_on_data\u001b[1;34m(train_path, test_path)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m     \u001b[0mgraph_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_and_eval_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_in_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_out_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_uids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_in_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_out_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_uids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_in_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_out_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_uids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19088\\845619189.py\u001b[0m in \u001b[0;36mtrain_and_eval_graph\u001b[1;34m(sim, train_in_tensor, train_out_tensor, train_uids, val_in_tensor, val_out_tensor, val_uids, test_in_tensor, test_out_tensor, test_uids)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mtrain_graph_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19088\\3840471047.py\u001b[0m in \u001b[0;36mtrain_graph_model\u001b[1;34m(model, train, val, n_epochs)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mbatch_Y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_Y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mrecons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19088\\2008905878.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, uids)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muids\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[0mneighbors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0muid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0muids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19088\\2008905878.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muids\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[0mneighbors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0muid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0muids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\nick\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2098\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2099\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2100\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nick\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2100\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2101\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[1;32m-> 2102\u001b[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[0;32m   2103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2104\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nick\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1368\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nick\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1268\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1269\u001b[0m             )\n\u001b[0;32m   1270\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Minimal'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nick\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[1;32m-> 1125\u001b[1;33m                                                                tb_offset)\n\u001b[0m\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[1;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nick\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nick\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "compare_on_data(datapath(f\"train/uniform/uniform100_data.pt\"), datapath(f\"test/uniform/uniform100_test_indices.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_on_data(datapath(f\"full_data.pt\"), datapath(f\"full_data_test_indices.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
