{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nick\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# This needs to be here because by default Jupyter only adds the pwd to sys.path\n",
    "import os, sys\n",
    "if os.path.abspath('..') not in sys.path: sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pysrc.constants import datapath, N_ITEMS, N_USERS\n",
    "from pysrc.constants import cachepath, datapath, chartpath\n",
    "import torch\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {}\n",
    "test_dict = {}\n",
    "\n",
    "with open(datapath(\"train.txt\")) as file:\n",
    "    for line in file:\n",
    "        (user_id, items) = line.split(maxsplit=1)\n",
    "        train_dict[user_id] = items\n",
    "\n",
    "with open(datapath(\"test.txt\")) as file:\n",
    "    for line in file:\n",
    "        split = line.split(maxsplit=1)\n",
    "        if (len(split) > 1):\n",
    "            (user_id, items) = split\n",
    "            test_dict[user_id] = items\n",
    "        else:\n",
    "            test_dict[split[0]] = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "test = []\n",
    "for key in train_dict:\n",
    "    train.append([int(n) for n in train_dict[key].replace('\\n', '').split(' ')])\n",
    "\n",
    "for key in test_dict:\n",
    "    if len(test_dict[key]) == 0:\n",
    "        test.append([])\n",
    "    else:\n",
    "        test.append([int(n) for n in test_dict[key].replace('\\n', '').split(' ')])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6549, 0.1126, 0.4032, 0.7733, 0.0327],\n",
       "        [0.8138, 0.1709, 0.8036, 0.7272, 0.7437],\n",
       "        [0.1680, 0.4966, 0.6994, 0.0938, 0.4513],\n",
       "        [0.7882, 0.2402, 0.9304, 0.0371, 0.6274],\n",
       "        [0.3818, 0.1541, 0.0659, 0.5173, 0.5138],\n",
       "        [0.0113, 0.3439, 0.6384, 0.5857, 0.4727],\n",
       "        [0.9113, 0.9656, 0.1257, 0.8299, 0.7503],\n",
       "        [0.3561, 0.6170, 0.0706, 0.6356, 0.2207],\n",
       "        [0.8841, 0.5299, 0.0212, 0.6150, 0.2283],\n",
       "        [0.4835, 0.0285, 0.9788, 0.4322, 0.6307]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((10,5))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def log_likelihood_loss(y, yhat):\n",
    "    return -torch.mean(torch.sum(torch.log(yhat+1e-6) * y, axis = 1))\n",
    "\n",
    "def likelihood_loss(y, yhat):\n",
    "    return -torch.mean(torch.sum(yhat * y, axis = 1))\n",
    "\n",
    "class VanillaVAE(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 latent_dim: int,\n",
    "                 hidden_dims = None,\n",
    "                 kl_weight = .2\n",
    "                 ):\n",
    "        super(VanillaVAE, self).__init__()\n",
    "        \n",
    "        self.kl_weight = kl_weight\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        modules = []\n",
    "        \n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [512, 128]\n",
    "            \n",
    "        self.hidden_dims = hidden_dims\n",
    "            \n",
    "        modules.append(nn.Linear(input_dim, hidden_dims[0]))\n",
    "        modules.append(nn.BatchNorm1d(hidden_dims[0]))\n",
    "        modules.append(nn.LeakyReLU())\n",
    "        \n",
    "        # Build Encoder\n",
    "        for i in range(len(hidden_dims)-1):\n",
    "            modules.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n",
    "            modules.append(nn.BatchNorm1d(hidden_dims[i+1]))\n",
    "            modules.append(nn.LeakyReLU())\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "        self.fc_mu = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "        self.fc_var = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "\n",
    "        # Build Decoder\n",
    "        modules = []\n",
    "\n",
    "        self.decoder_input = nn.Linear(latent_dim, hidden_dims[-1])\n",
    "\n",
    "        hidden_dims.reverse()\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n",
    "            modules.append(nn.BatchNorm1d(hidden_dims[i+1]))\n",
    "            modules.append(nn.LeakyReLU())\n",
    "\n",
    "\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "        self.final_layer = nn.Sequential(nn.Linear(hidden_dims[-1], input_dim),\n",
    "                                         nn.Sigmoid()\n",
    "                                        )\n",
    "        \n",
    "\n",
    "    def encode(self, input: Tensor):\n",
    "        \"\"\"\n",
    "        Encodes the input by passing through the encoder network\n",
    "        and returns the latent codes.\n",
    "        :param input: (Tensor) Input tensor to encoder [N x C x H x W]\n",
    "        :return: (Tensor) List of latent codes\n",
    "        \"\"\"\n",
    "        result = self.encoder(input)\n",
    "        result = torch.flatten(result, start_dim=1)\n",
    "\n",
    "        # Split the result into mu and var components\n",
    "        # of the latent Gaussian distribution\n",
    "        mu = self.fc_mu(result)\n",
    "        log_var = self.fc_var(result)\n",
    "\n",
    "        return [mu, log_var]\n",
    "\n",
    "    def decode(self, z: Tensor):\n",
    "        \"\"\"\n",
    "        Maps the given latent codes\n",
    "        onto the image space.\n",
    "        :param z: (Tensor) [B x D]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "        result = self.decoder_input(z)\n",
    "        result = result.view(-1, self.hidden_dims[0])\n",
    "        result = self.decoder(result)\n",
    "        result = self.final_layer(result)\n",
    "        result = F.normalize(result, p=1)\n",
    "        return result\n",
    "\n",
    "    def reparameterize(self, mu: Tensor, logvar: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Reparameterization trick to sample from N(mu, var) from\n",
    "        N(0,1).\n",
    "        :param mu: (Tensor) Mean of the latent Gaussian [B x D]\n",
    "        :param logvar: (Tensor) Standard deviation of the latent Gaussian [B x D]\n",
    "        :return: (Tensor) [B x D]\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "\n",
    "    def forward(self, x: Tensor, **kwargs):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        return  [F.normalize(self.decode(z), 1, dim=1), x, mu, log_var]\n",
    "\n",
    "    def loss_function(self, recons, x, mu, log_var) -> dict:\n",
    "        \"\"\"\n",
    "        Computes the VAE loss function.\n",
    "        KL(N(\\mu, \\sigma), N(0, 1)) = \\log \\frac{1}{\\sigma} + \\frac{\\sigma^2 + \\mu^2}{2} - \\frac{1}{2}\n",
    "        :param args:\n",
    "        :param kwargs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        kld_weight = self.kl_weight\n",
    "        recons_loss = log_likelihood_loss(x, recons)\n",
    "\n",
    "        kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1), dim = 0)\n",
    "\n",
    "        loss = recons_loss + kld_weight * kld_loss\n",
    "        return {'loss': loss, 'Reconstruction_Loss':recons_loss.detach(), 'KLD':-kld_loss.detach()}\n",
    "\n",
    "    def sample(self,\n",
    "               num_samples:int,\n",
    "               current_device: int, **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the latent space and return the corresponding\n",
    "        image space map.\n",
    "        :param num_samples: (Int) Number of samples\n",
    "        :param current_device: (Int) Device to run the model\n",
    "        :return: (Tensor)\n",
    "        \"\"\"\n",
    "        z = torch.randn(num_samples,\n",
    "                        self.latent_dim)\n",
    "\n",
    "        z = z.to(current_device)\n",
    "\n",
    "        samples = self.decode(z)\n",
    "        return samples\n",
    "\n",
    "    def generate(self, x: Tensor, **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Given an input image x, returns the reconstructed image\n",
    "        :param x: (Tensor) [B x C x H x W]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "\n",
    "        return self.forward(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_dim = N_ITEMS\n",
    "np.random.seed(0)\n",
    "test_ids = np.random.choice(np.array(list(train_dict.keys())).astype(int), int(.2*len(train_dict.keys())), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsify_uniform(data, p_relative = .1):\n",
    "    current_sparse = None\n",
    "    batch_size = 1000\n",
    "    X = []\n",
    "    for row in data:\n",
    "        X.append(torch.zeros(N_ITEMS).bool())\n",
    "        for item in row:\n",
    "            if np.random.random() > p_relative:\n",
    "                X[-1][item] = 1\n",
    "        X[-1] = X[-1]\n",
    "    X = torch.stack(X)\n",
    "    return X\n",
    "    \n",
    "def sparsify_items(data, m, sigma):\n",
    "    return\n",
    "\n",
    "def sparsify_users(data, m, sigma):\n",
    "    return\n",
    "\n",
    "def list_batch_to_ohe(data):\n",
    "    return sparsify_uniform(data, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train, val, n_epochs = 100):\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "        total_loading_time = 0\n",
    "        for batch_X, batch_Y in train:\n",
    "            batch_X = batch_X.float()\n",
    "            batch_Y = batch_Y.float()\n",
    "            recons, x, mu, log_var = model.forward(batch_X)\n",
    "            train_loss = model.loss_function(recons, batch_Y, mu, log_var)['loss']\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                total_train_loss = 0\n",
    "                r_train_loss = 0\n",
    "                kl_train_loss = 0\n",
    "                train_batches = 0\n",
    "                for batch_X, batch_Y in train:\n",
    "                    batch_X = batch_X.float().cuda()\n",
    "                    recons, x, mu, log_var = model.forward(batch_X)\n",
    "                    loss = model.loss_function(recons, batch_X, mu, log_var)\n",
    "                    total_train_loss += loss['loss']\n",
    "                    r_train_loss += loss['Reconstruction_Loss']\n",
    "                    kl_train_loss += loss['KLD']\n",
    "                    train_batches += 1\n",
    "\n",
    "                total_train_loss /= train_batches\n",
    "                r_train_loss /= train_batches\n",
    "                kl_train_loss /= train_batches\n",
    "\n",
    "                total_loss = 0\n",
    "                r_loss = 0\n",
    "                kl_loss = 0\n",
    "                batches = 0\n",
    "                for batch_X, batch_Y in val:\n",
    "                    batch_X = batch_X.float().cuda()\n",
    "                    recons, x, mu, log_var = model.forward(batch_X)\n",
    "                    loss = model.loss_function(recons, batch_X, mu, log_var)\n",
    "                    total_loss += loss['loss']\n",
    "                    r_loss += loss['Reconstruction_Loss']\n",
    "                    kl_loss += loss['KLD']\n",
    "                    batches += 1\n",
    "\n",
    "                total_loss /= batches\n",
    "                r_loss /= batches\n",
    "                kl_loss /= batches\n",
    "                \n",
    "            print(\"Train Loss\", total_train_loss)\n",
    "            print(\"Val Loss\", total_loss)\n",
    "            \n",
    "def train_model_old(model, train, val, n_epochs = 100):\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Start Epoch {epoch}\")\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "        total_loading_time = 0\n",
    "        for batch_X, batch_Y in train:\n",
    "            batch_X = batch_X.float().cuda()\n",
    "            recons, x, mu, log_var = model.forward(batch_X)\n",
    "            train_loss = model.loss_function(recons, batch_X, mu, log_var)['loss']\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        '''\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            total_train_loss = 0\n",
    "            r_train_loss = 0\n",
    "            kl_train_loss = 0\n",
    "            train_batches = 0\n",
    "            for batch_X, batch_Y in train:\n",
    "                batch_X = batch_X.float().cuda()\n",
    "                recons, x, mu, log_var = model.forward(batch_X)\n",
    "                loss = model.loss_function(recons, batch_X, mu, log_var)\n",
    "                total_train_loss += loss['loss']\n",
    "                r_train_loss += loss['Reconstruction_Loss']\n",
    "                kl_train_loss += loss['KLD']\n",
    "                train_batches += 1\n",
    "\n",
    "            total_train_loss /= train_batches\n",
    "            r_train_loss /= train_batches\n",
    "            kl_train_loss /= train_batches\n",
    "\n",
    "            total_loss = 0\n",
    "            r_loss = 0\n",
    "            kl_loss = 0\n",
    "            batches = 0\n",
    "            for batch_X, batch_Y in val:\n",
    "                batch_X = batch_X.float().cuda()\n",
    "                recons, x, mu, log_var = model.forward(batch_X)\n",
    "                loss = model.loss_function(recons, batch_X, mu, log_var)\n",
    "                total_loss += loss['loss']\n",
    "                r_loss += loss['Reconstruction_Loss']\n",
    "                kl_loss += loss['KLD']\n",
    "                batches += 1\n",
    "\n",
    "            total_loss /= batches\n",
    "            r_loss /= batches\n",
    "            kl_loss /= batches\n",
    "        '''\n",
    "def top_k_recall(X_in, X_out, X_target, k = 20, mask_in = True):\n",
    "    if mask_in:\n",
    "        mask = X_in == False\n",
    "        X_out = X_out * mask\n",
    "    topk = torch.topk(X_out, k)\n",
    "    n = 0\n",
    "    total_recall = 0\n",
    "    for i in range(len(X_in)):\n",
    "        if int(X_target[i].sum()) == 0:\n",
    "            continue\n",
    "        selected = topk.indices[i]\n",
    "        total_recall += X_target[i][selected].sum() / X_target[i].sum()\n",
    "        n += 1\n",
    "    \n",
    "    return total_recall / n\n",
    "\n",
    "def n_recall(X_in, X_out, X_target, mask_in = True):\n",
    "    if mask_in:\n",
    "        mask = X_in == False\n",
    "        X_out = X_out * mask\n",
    "        X_target = X_target * mask\n",
    "    topk = torch.topk(X_out, int(X_target.sum(axis=1).max()), sorted=True)\n",
    "    n = 0\n",
    "    total_recall = 0\n",
    "    for i in range(len(X_in)):\n",
    "        if int(X_target[i].sum()) == 0:\n",
    "            continue\n",
    "        selected = topk.indices[i]\n",
    "        total_recall += X_target[i][selected[:int(X_target[i].sum())]].sum() / int(X_target[i].sum())\n",
    "        n += 1\n",
    "    #print(total_recall,n)\n",
    "    #print(len(X_in))\n",
    "    return total_recall / len(X_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This needs to be here because by default Jupyter only adds the pwd to sys.path\n",
    "import os, sys\n",
    "if os.path.abspath('..') not in sys.path: sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import scipy\n",
    "import pickle \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from pysrc.constants import datapath#, N_ITEMS, N_USERS\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_jaccard_sparse(csr):\n",
    "    \"\"\"Computes the Jaccard distance between the rows of `csr`,\n",
    "    smaller than the cut-off distance `epsilon`.\n",
    "    \"\"\"\n",
    "    csr = csr_matrix(csr).astype(bool).astype(int)\n",
    "\n",
    "    csr_rownnz = csr.getnnz(axis=1)\n",
    "    intrsct = csr.dot(csr.T)\n",
    "\n",
    "    nnz_i = np.repeat(csr_rownnz, intrsct.getnnz(axis=1))\n",
    "    unions = nnz_i + csr_rownnz[intrsct.indices] - intrsct.data\n",
    "    dists = intrsct.data / unions\n",
    "\n",
    "    out = csr_matrix((dists, intrsct.indices, intrsct.indptr), intrsct.shape)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsify_sparse_uniform(sparse_X, p_relative = .1):\n",
    "    X = []\n",
    "    for i in range(sparse_train_data.shape[0]):\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "        X.append(torch.zeros(item_dim).bool())\n",
    "        row = sparse_X[i].coalesce().indices()[0]\n",
    "        X[-1][row] = 1\n",
    "    X = torch.stack(X)\n",
    "    return X\n",
    "    \n",
    "def sparse_to_ohe(data):\n",
    "    return sparsify_sparse_uniform(data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "def log_likelihood_loss(y, yhat):\n",
    "    return -torch.mean(torch.sum(torch.log(yhat+1e-6) * y, axis = 1))\n",
    "\n",
    "def likelihood_loss(y, yhat):\n",
    "    return -torch.mean(torch.sum(yhat * y, axis = 1))\n",
    "\n",
    "class GraphVAE(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 latent_dim: int,\n",
    "                 hidden_dims = None,\n",
    "                 kl_weight = .2,\n",
    "                 sim = None\n",
    "                 ):\n",
    "        super(GraphVAE, self).__init__()\n",
    "        \n",
    "        self.kl_weight = kl_weight\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.embeddings = torch.zeros(N_USERS, self.latent_dim).cuda()\n",
    "        \n",
    "        coo = sim.tocoo()\n",
    "        \n",
    "        values = coo.data\n",
    "        indices = np.vstack((coo.row, coo.col))\n",
    "\n",
    "        i = torch.LongTensor(indices)\n",
    "        v = torch.FloatTensor(values)\n",
    "        shape = coo.shape\n",
    "\n",
    "        self.neighbors = torch.sparse.FloatTensor(i, v, torch.Size(shape)).cuda()\n",
    "\n",
    "        self.neighbors_norms = torch.zeros(self.neighbors.shape[0]).cuda()\n",
    "        \n",
    "        for i in range(self.neighbors.shape[0]):\n",
    "            self.neighbors_norms[i] = torch.sum(self.neighbors[i].coalesce().values())\n",
    "            \n",
    "        self.embeddings.requires_grad = False\n",
    "        self.neighbors_norms.requires_grad = False\n",
    "        self.neighbors.requires_grad = False\n",
    "        \n",
    "        modules = []\n",
    "        \n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [512, 128]\n",
    "            \n",
    "        self.hidden_dims = hidden_dims\n",
    "            \n",
    "        modules.append(nn.Linear(input_dim, hidden_dims[0]))\n",
    "        modules.append(nn.BatchNorm1d(hidden_dims[0]))\n",
    "        modules.append(nn.LeakyReLU())\n",
    "        \n",
    "        # Build Encoder\n",
    "        for i in range(len(hidden_dims)-1):\n",
    "            modules.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n",
    "            modules.append(nn.BatchNorm1d(hidden_dims[i+1]))\n",
    "            modules.append(nn.LeakyReLU())\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "        self.fc_mu = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "        self.fc_var = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "\n",
    "        # Build Decoder\n",
    "        modules = []\n",
    "\n",
    "        self.decoder_input = nn.Linear(2 * latent_dim, hidden_dims[-1])\n",
    "\n",
    "        hidden_dims.reverse()\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n",
    "            modules.append(nn.BatchNorm1d(hidden_dims[i+1]))\n",
    "            modules.append(nn.LeakyReLU())\n",
    "\n",
    "\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "        self.final_layer = nn.Sequential(nn.Linear(hidden_dims[-1], input_dim),\n",
    "                                         nn.Sigmoid()\n",
    "                                        )\n",
    "        \n",
    "\n",
    "    def encode(self, input: Tensor):\n",
    "        \"\"\"\n",
    "        Encodes the input by passing through the encoder network\n",
    "        and returns the latent codes.\n",
    "        :param input: (Tensor) Input tensor to encoder [N x C x H x W]\n",
    "        :return: (Tensor) List of latent codes\n",
    "        \"\"\"\n",
    "        result = self.encoder(input)\n",
    "        result = torch.flatten(result, start_dim=1)\n",
    "        # Split the result into mu and var components\n",
    "        # of the latent Gaussian distribution\n",
    "        mu = self.fc_mu(result)\n",
    "        log_var = self.fc_var(result)\n",
    "\n",
    "        return [mu, log_var]\n",
    "\n",
    "    def decode(self, z: Tensor):\n",
    "        \"\"\"\n",
    "        Maps the given latent codes\n",
    "        onto the image space.\n",
    "        :param z: (Tensor) [B x D]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "        result = self.decoder_input(z)\n",
    "        result = result.view(-1, self.hidden_dims[0])\n",
    "        result = self.decoder(result)\n",
    "        result = self.final_layer(result)\n",
    "        result = F.normalize(result, p=1)\n",
    "        return result\n",
    "\n",
    "    def reparameterize(self, mu: Tensor, logvar: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Reparameterization trick to sample from N(mu, var) from\n",
    "        N(0,1).\n",
    "        :param mu: (Tensor) Mean of the latent Gaussian [B x D]\n",
    "        :param logvar: (Tensor) Standard deviation of the latent Gaussian [B x D]\n",
    "        :return: (Tensor) [B x D]\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "\n",
    "    def forward(self, x: Tensor, uids):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        self.embeddings[uids] = z.detach()\n",
    "        \n",
    "        neighbors = torch.stack([self.neighbors[uid].to_dense() for uid in uids])\n",
    "        \n",
    "        neighbor_embeds = ((neighbors @ self.embeddings).T / (self.neighbors_norms[uids] + 1e-5)).T\n",
    "        \n",
    "        z = torch.cat([z, neighbor_embeds], axis=1)\n",
    "        \n",
    "        return  [F.normalize(self.decode(z), 1, dim=1), x, mu, log_var]\n",
    "    \n",
    "        \n",
    "    def set_embeddings(self, x, uids):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        self.embeddings[uids] = z.detach()\n",
    "\n",
    "    def loss_function(self, recons, x, mu, log_var) -> dict:\n",
    "        \"\"\"\n",
    "        Computes the VAE loss function.\n",
    "        KL(N(\\mu, \\sigma), N(0, 1)) = \\log \\frac{1}{\\sigma} + \\frac{\\sigma^2 + \\mu^2}{2} - \\frac{1}{2}\n",
    "        :param args:\n",
    "        :param kwargs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        kld_weight = self.kl_weight\n",
    "        recons_loss = log_likelihood_loss(x, recons)\n",
    "\n",
    "        kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1), dim = 0)\n",
    "\n",
    "        loss = recons_loss + kld_weight * kld_loss\n",
    "        return {'loss': loss, 'Reconstruction_Loss':recons_loss.detach(), 'KLD':-kld_loss.detach()}\n",
    "\n",
    "    def sample(self,\n",
    "               num_samples:int,\n",
    "               current_device: int, **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the latent space and return the corresponding\n",
    "        image space map.\n",
    "        :param num_samples: (Int) Number of samples\n",
    "        :param current_device: (Int) Device to run the model\n",
    "        :return: (Tensor)\n",
    "        \"\"\"\n",
    "        z = torch.randn(num_samples,\n",
    "                        self.latent_dim)\n",
    "\n",
    "        z = z.to(current_device)\n",
    "\n",
    "        samples = self.decode(z)\n",
    "        return samples\n",
    "\n",
    "    def generate(self, x: Tensor, **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Given an input image x, returns the reconstructed image\n",
    "        :param x: (Tensor) [B x C x H x W]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "\n",
    "        return self.forward(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_graph_model(model, train, val, n_epochs = 100):\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "    \n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "        total_loading_time = 0\n",
    "        for batch_X, batch_Y, batch_ind in train:\n",
    "            batch_X = batch_X.float()\n",
    "            batch_Y = batch_Y.float()\n",
    "            recons, x, mu, log_var = model.forward(batch_X, batch_ind)\n",
    "            train_loss = model.loss_function(recons, batch_Y, mu, log_var)['loss']\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        print(time.time() - start_time)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Done Epoch {epoch}\")\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                total_train_loss = 0\n",
    "                r_train_loss = 0\n",
    "                kl_train_loss = 0\n",
    "                train_batches = 0\n",
    "                for batch_X, batch_Y, batch_ind in train:\n",
    "                    batch_X = batch_X.float()\n",
    "                    batch_Y = batch_Y.float()\n",
    "                    recons, x, mu, log_var = model.forward(batch_X, batch_ind)\n",
    "                    loss = model.loss_function(recons, batch_Y, mu, log_var)\n",
    "                    total_train_loss += loss['loss']\n",
    "                    r_train_loss += loss['Reconstruction_Loss']\n",
    "                    kl_train_loss += loss['KLD']\n",
    "                    train_batches += 1\n",
    "\n",
    "                total_train_loss /= train_batches\n",
    "                r_train_loss /= train_batches\n",
    "                kl_train_loss /= train_batches\n",
    "\n",
    "                total_loss = 0\n",
    "                r_loss = 0\n",
    "                kl_loss = 0\n",
    "                batches = 0\n",
    "                for batch_X, batch_Y, batch_ind in val:\n",
    "                    batch_X = batch_X.float().cuda()\n",
    "                    batch_Y = batch_Y.float().cuda()\n",
    "                    recons, x, mu, log_var = model.forward(batch_X, batch_ind)\n",
    "                    loss = model.loss_function(recons, batch_Y, mu, log_var)\n",
    "                    total_loss += loss['loss']\n",
    "                    r_loss += loss['Reconstruction_Loss']\n",
    "                    kl_loss += loss['KLD']\n",
    "                    batches += 1\n",
    "\n",
    "                total_loss /= batches\n",
    "                r_loss /= batches\n",
    "                kl_loss /= batches\n",
    "                \n",
    "            print(\"Train Loss\", total_train_loss)\n",
    "            print(\"Val Loss\", total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256 \n",
    "def train_and_eval_base(train_in_tensor, train_out_tensor, val_in_tensor, val_out_tensor, test_in_tensor, test_out_tensor):\n",
    "    train_dataset = TensorDataset(train_in_tensor.cuda(), (train_in_tensor + train_out_tensor).cuda())\n",
    "    val_dataset = TensorDataset(val_in_tensor, val_in_tensor + val_out_tensor)\n",
    "    test_dataset = TensorDataset(test_in_tensor, test_in_tensor + test_out_tensor)\n",
    "    # Create a data loader from the dataset\n",
    "    # Type of sampling and batch size are specified at this step\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    lr = 1e-3\n",
    "    model = VanillaVAE(input_dim = item_dim, latent_dim = 256, hidden_dims = [512, 256], kl_weight = 1).cuda()\n",
    "    print(\"starting training\")\n",
    "    train_model(model, train_dataloader, val_dataloader, n_epochs = 120)\n",
    "    print(\"starting eval\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_n_recall_train = 0\n",
    "        total_n_train = 0\n",
    "        for batch_X, batch_Y in train_dataloader:\n",
    "            batch_out = model.forward(batch_X.float().cuda())[0].detach().cuda()\n",
    "            n_recall_batch = n_recall(batch_X.cuda(), batch_out.cuda(), batch_X.cuda(), False)\n",
    "            total_n_recall_train += n_recall_batch * len(batch_X)\n",
    "            total_n_train += len(batch_X)\n",
    "        print(\"Train recons recall:\", total_n_recall_train / total_n_train)\n",
    "        train_recons_recall = total_n_recall_train / total_n_train\n",
    "        \n",
    "        total_n_recall_out = 0\n",
    "        total_n_out = 0\n",
    "        for batch_X, batch_Y in train_dataloader:\n",
    "            batch_out = model.forward(batch_X.float().cuda())[0].detach().cuda()\n",
    "            n_recall_batch = n_recall(batch_X.cuda(), batch_out.cuda(), batch_Y.cuda(), True)\n",
    "            total_n_recall_out += n_recall_batch * len(batch_X)\n",
    "            total_n_out += len(batch_X)\n",
    "        print(\"Train pred recall:\", total_n_recall_out / total_n_out)\n",
    "        train_outsample_recall = total_n_recall_out / total_n_out\n",
    "        \n",
    "        total_n_recall_recons = 0\n",
    "        total_n_recons = 0\n",
    "        for batch_X, batch_Y in test_dataloader:\n",
    "            batch_out = model.forward(batch_X.float().cuda())[0].detach().cuda()\n",
    "            n_recall_batch = n_recall(batch_X.cuda(), batch_out.cuda(), batch_X.cuda(), False)\n",
    "            total_n_recall_recons += n_recall_batch * len(batch_X)\n",
    "            total_n_recons += len(batch_X)\n",
    "        print(\"Test recons recall:\", total_n_recall_recons / total_n_recons)\n",
    "        test_recons_recall = total_n_recall_recons / total_n_recons\n",
    "        \n",
    "        total_n_recall_out = 0\n",
    "        total_n_out = 0\n",
    "        for batch_X, batch_Y in test_dataloader:\n",
    "            batch_out = model.forward(batch_X.float().cuda())[0].detach().cuda()\n",
    "            n_recall_batch = n_recall(batch_X.cuda(), batch_out.cuda(), batch_Y.cuda(), True)\n",
    "            total_n_recall_out += n_recall_batch * len(batch_X)\n",
    "            total_n_out += len(batch_X)\n",
    "        print(\"Test outsample recall:\", total_n_recall_out / total_n_out)\n",
    "        test_outsample_recall = total_n_recall_out / total_n_out\n",
    "    return model, {\"train_recons\": train_recons_recall, \"train_out\": train_outsample_recall, \"test_recons\": test_recons_recall, \"test_out\": test_outsample_recall}\n",
    "\n",
    "def train_and_eval_graph(sim, train_in_tensor, train_out_tensor, train_uids, val_in_tensor, val_out_tensor, val_uids, test_in_tensor, test_out_tensor, test_uids):\n",
    "    train_dataset = TensorDataset(train_in_tensor.cuda(), (train_in_tensor + train_out_tensor).cuda(), train_uids.cuda())\n",
    "    val_dataset = TensorDataset(val_in_tensor, val_in_tensor + val_out_tensor, val_uids)\n",
    "    test_dataset = TensorDataset(test_in_tensor, test_in_tensor + test_out_tensor, test_uids)\n",
    "    # Create a data loader from the dataset\n",
    "    # Type of sampling and batch size are specified at this step\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    lr = 1e-3\n",
    "    model = GraphVAE(input_dim = item_dim, latent_dim = 256, hidden_dims = [512, 256], kl_weight = 1, sim = sim).cuda()\n",
    "    print(\"starting training\")\n",
    "    train_graph_model(model, train_dataloader, val_dataloader, n_epochs = 120)\n",
    "    print(\"starting eval\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_Y, batch_ind in train_dataloader:\n",
    "            model.set_embeddings(batch_X.float().cuda(), batch_ind)\n",
    "        for batch_X, batch_Y, batch_ind in val_dataloader:\n",
    "            model.set_embeddings(batch_X.float().cuda(), batch_ind)\n",
    "        for batch_X, batch_Y, batch_ind in test_dataloader:\n",
    "            model.set_embeddings(batch_X.float().cuda(), batch_ind)\n",
    "\n",
    "        total_n_recall_recons = 0\n",
    "        total_n_recons = 0\n",
    "        for batch_X, batch_Y, batch_ind in train_dataloader:\n",
    "            batch_out = model.forward(batch_X.float().cuda(), batch_ind)[0].detach().cuda()\n",
    "            n_recall_batch = n_recall(batch_X.cuda(), batch_out.cuda(), batch_X.cuda(), False)\n",
    "            total_n_recall_recons += n_recall_batch * len(batch_ind)\n",
    "            total_n_recons += len(batch_ind)\n",
    "        print(\"Train recons recall:\", total_n_recall_recons / total_n_recons)\n",
    "        train_recons_recall = total_n_recall_recons / total_n_recons\n",
    "\n",
    "\n",
    "        total_n_recall_out = 0\n",
    "        total_n_out = 0\n",
    "        for batch_X, batch_Y, batch_ind in train_dataloader:\n",
    "            batch_out = model.forward(batch_X.float().cuda(), batch_ind)[0].detach().cuda()\n",
    "            n_recall_batch = n_recall(batch_X.cuda(), batch_out.cuda(), batch_Y.cuda(), True)\n",
    "            total_n_recall_out += n_recall_batch * len(batch_X)\n",
    "            total_n_out += len(batch_X)\n",
    "        print(\"Train outsample recall:\", total_n_recall_out / total_n_out)\n",
    "        train_outsample_recall = total_n_recall_out / total_n_out\n",
    "\n",
    "        total_n_recall_recons = 0\n",
    "        total_n_recons = 0\n",
    "        for batch_X, batch_Y, batch_ind in test_dataloader:\n",
    "            batch_out = model.forward(batch_X.float().cuda(), batch_ind)[0].detach().cuda()\n",
    "            n_recall_batch = n_recall(batch_X.cuda(), batch_out.cuda(), batch_X.cuda(), False)\n",
    "            total_n_recall_recons += n_recall_batch * len(batch_X)\n",
    "            total_n_recons += len(batch_X)\n",
    "        print(\"Test recons recall:\", total_n_recall_recons / total_n_recons)\n",
    "        test_recons_recall = total_n_recall_recons / total_n_recons\n",
    "\n",
    "\n",
    "        total_n_recall_out = 0\n",
    "        total_n_out = 0\n",
    "        for batch_X, batch_Y, batch_ind in test_dataloader:\n",
    "            batch_out = model.forward(batch_X.float().cuda(), batch_ind)[0].detach().cuda()\n",
    "            n_recall_batch = n_recall(batch_X.cuda(), batch_out.cuda(), batch_Y.cuda(), True)\n",
    "            total_n_recall_out += n_recall_batch * len(batch_ind)\n",
    "            total_n_out += len(batch_ind)\n",
    "        print(\"Test outsample recall:\", total_n_recall_out / total_n_out)\n",
    "        test_outsample_recall = total_n_recall_out / total_n_out\n",
    "    return model, {\"train_recons\": train_recons_recall, \"train_out\": train_outsample_recall, \"test_recons\": test_recons_recall, \"test_out\": test_outsample_recall}\n",
    "\n",
    "def compare_on_data(train_path, test_path):\n",
    "    sparse_train_data = torch.load(train_path)\n",
    "    sparse_test_data = pickle.load(open(test_path, \"rb\"))\n",
    "    sim = pairwise_jaccard_sparse(sparse_train_data.to_dense())\n",
    "    for i in range(sim.shape[0]):\n",
    "        sim[i,i] = 0\n",
    "    dev_df = sparse_train_data.bool().to_dense()\n",
    "    test_df = list_batch_to_ohe(pd.Series(sparse_test_data))\n",
    "    test_mask = torch.zeros(dev_df.shape[0])\n",
    "    test_mask[test_ids[test_ids < dev_df.shape[0]]] = 1\n",
    "    \n",
    "    print(dev_df.shape, test_df.shape, test_mask.shape)\n",
    "    \n",
    "    dev_in = dev_df[test_mask == 0]\n",
    "    dev_out = test_df[test_mask == 0]\n",
    "    test_in_tensor = dev_df[test_mask == 1]\n",
    "    test_out_tensor = test_df[test_mask == 1]\n",
    "\n",
    "    train_uids = (1-test_mask).nonzero().reshape(-1)[:int(.7*len(dev_in))]\n",
    "    val_uids = (1-test_mask).nonzero().reshape(-1)[int(.7*len(dev_in)):]\n",
    "    test_uids = test_mask.nonzero().reshape(-1)\n",
    "\n",
    "    train_in_tensor = dev_in[:int(.7*len(dev_in))]\n",
    "    val_in_tensor = dev_in[int(.7*len(dev_in)):]\n",
    "\n",
    "    train_out_tensor = dev_out[:int(.7*len(dev_in))]\n",
    "    val_out_tensor = dev_out[int(.7*len(dev_in)):]\n",
    "    \n",
    "    graph_model, graph_results = train_and_eval_graph(sim, train_in_tensor, train_out_tensor, train_uids, val_in_tensor, val_out_tensor, val_uids, test_in_tensor, test_out_tensor, test_uids)\n",
    "    \n",
    "    base_model, base_results = train_and_eval_base(train_in_tensor, train_out_tensor, val_in_tensor, val_out_tensor, test_in_tensor, test_out_tensor)\n",
    "    \n",
    "    return base_model, base_results, graph_model, graph_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nick\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\sparse\\_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 9159]) torch.Size([10000, 9159]) torch.Size([10000])\n",
      "starting training\n",
      "5.492177963256836\n",
      "Done Epoch 0\n",
      "Train Loss tensor(69.5616, device='cuda:0')\n",
      "Val Loss tensor(57.8375, device='cuda:0')\n",
      "4.873860120773315\n",
      "4.882201194763184\n",
      "4.935052394866943\n",
      "4.9026243686676025\n",
      "4.867415189743042\n",
      "4.867654323577881\n",
      "4.872686862945557\n",
      "4.886162042617798\n",
      "4.870603561401367\n",
      "4.871131658554077\n",
      "Done Epoch 10\n",
      "Train Loss tensor(67.0886, device='cuda:0')\n",
      "Val Loss tensor(57.9008, device='cuda:0')\n",
      "4.826723098754883\n",
      "4.777587413787842\n",
      "4.699201345443726\n",
      "4.790892839431763\n",
      "4.947161436080933\n",
      "4.89592170715332\n",
      "4.906963109970093\n",
      "4.939250946044922\n",
      "4.880144119262695\n",
      "4.93905234336853\n",
      "Done Epoch 20\n",
      "Train Loss tensor(64.8387, device='cuda:0')\n",
      "Val Loss tensor(57.7345, device='cuda:0')\n",
      "4.8778111934661865\n",
      "4.916743040084839\n",
      "4.883239269256592\n",
      "4.875119209289551\n",
      "4.9431586265563965\n",
      "4.906879901885986\n",
      "4.828272342681885\n",
      "4.983246088027954\n",
      "4.8970725536346436\n",
      "4.902690649032593\n",
      "Done Epoch 30\n",
      "Train Loss tensor(63.5308, device='cuda:0')\n",
      "Val Loss tensor(56.6294, device='cuda:0')\n",
      "4.8691627979278564\n",
      "4.765642881393433\n",
      "4.772106170654297\n",
      "4.763543605804443\n",
      "4.902225732803345\n",
      "4.959237098693848\n",
      "4.8974950313568115\n",
      "4.870511293411255\n",
      "4.85162091255188\n",
      "4.86617374420166\n",
      "Done Epoch 40\n",
      "Train Loss tensor(61.8251, device='cuda:0')\n",
      "Val Loss tensor(56.6074, device='cuda:0')\n",
      "4.856974840164185\n",
      "4.8624351024627686\n",
      "4.874053001403809\n",
      "4.86032509803772\n",
      "4.856297731399536\n",
      "4.8452301025390625\n",
      "4.870226860046387\n",
      "4.852052211761475\n",
      "4.869775056838989\n",
      "4.677561044692993\n",
      "Done Epoch 50\n",
      "Train Loss tensor(60.8603, device='cuda:0')\n",
      "Val Loss tensor(56.2076, device='cuda:0')\n",
      "4.11717677116394\n",
      "4.139685392379761\n",
      "4.11870265007019\n",
      "4.218604803085327\n",
      "4.173365116119385\n",
      "4.1663994789123535\n",
      "4.214914083480835\n",
      "4.135108947753906\n",
      "4.0567638874053955\n",
      "9.771179676055908\n",
      "Done Epoch 60\n",
      "Train Loss tensor(59.7680, device='cuda:0')\n",
      "Val Loss tensor(55.7730, device='cuda:0')\n",
      "10.557912588119507\n",
      "10.572129726409912\n",
      "5.85254430770874\n",
      "3.554192304611206\n",
      "3.563469648361206\n",
      "3.581061840057373\n",
      "3.7156260013580322\n",
      "2.7566561698913574\n",
      "2.180447816848755\n",
      "2.2718966007232666\n",
      "Done Epoch 70\n",
      "Train Loss tensor(59.2055, device='cuda:0')\n",
      "Val Loss tensor(55.9132, device='cuda:0')\n",
      "2.9138054847717285\n",
      "4.132070779800415\n",
      "4.088520288467407\n",
      "4.137627363204956\n",
      "4.143516778945923\n",
      "4.1023643016815186\n",
      "4.19035267829895\n",
      "3.0159969329833984\n",
      "1.984917163848877\n",
      "1.9793832302093506\n",
      "Done Epoch 80\n",
      "Train Loss tensor(58.5730, device='cuda:0')\n",
      "Val Loss tensor(54.8120, device='cuda:0')\n",
      "2.249622106552124\n",
      "2.0066633224487305\n",
      "2.0484564304351807\n",
      "2.0957043170928955\n",
      "2.078066349029541\n",
      "2.081432580947876\n",
      "2.102158546447754\n",
      "2.0724611282348633\n",
      "2.067470073699951\n",
      "2.08428692817688\n",
      "Done Epoch 90\n",
      "Train Loss tensor(58.0707, device='cuda:0')\n",
      "Val Loss tensor(55.3095, device='cuda:0')\n",
      "2.1013782024383545\n",
      "2.001025676727295\n",
      "2.0593223571777344\n",
      "2.045637607574463\n",
      "1.9959607124328613\n",
      "1.9872632026672363\n",
      "2.1360645294189453\n",
      "2.3107924461364746\n",
      "2.3412673473358154\n",
      "2.2546470165252686\n",
      "Done Epoch 100\n",
      "Train Loss tensor(57.7942, device='cuda:0')\n",
      "Val Loss tensor(54.2994, device='cuda:0')\n",
      "4.268045425415039\n",
      "4.225536584854126\n",
      "4.237860679626465\n",
      "4.26279878616333\n",
      "4.233782529830933\n",
      "4.28630256652832\n",
      "4.354225158691406\n",
      "5.005827188491821\n",
      "4.870863437652588\n",
      "4.839043140411377\n",
      "Done Epoch 110\n",
      "Train Loss tensor(57.3350, device='cuda:0')\n",
      "Val Loss tensor(54.6602, device='cuda:0')\n",
      "4.9210100173950195\n",
      "4.93896484375\n",
      "4.939388036727905\n",
      "4.910993337631226\n",
      "4.940618276596069\n",
      "4.461346864700317\n",
      "1.9717259407043457\n",
      "2.063551187515259\n",
      "1.9936480522155762\n",
      "starting eval\n",
      "Train recons recall: tensor(0.0444, device='cuda:0')\n",
      "Train outsample recall: tensor(0.0069, device='cuda:0')\n",
      "Test recons recall: tensor(0.0383, device='cuda:0')\n",
      "Test outsample recall: tensor(0.0056, device='cuda:0')\n",
      "starting training\n",
      "Train Loss tensor(55.0140, device='cuda:0')\n",
      "Val Loss tensor(46.3508, device='cuda:0')\n",
      "Train Loss tensor(53.2814, device='cuda:0')\n",
      "Val Loss tensor(45.9407, device='cuda:0')\n",
      "Train Loss tensor(52.5407, device='cuda:0')\n",
      "Val Loss tensor(45.4961, device='cuda:0')\n",
      "Train Loss tensor(51.8727, device='cuda:0')\n",
      "Val Loss tensor(45.2871, device='cuda:0')\n",
      "Train Loss tensor(51.2340, device='cuda:0')\n",
      "Val Loss tensor(45.8814, device='cuda:0')\n",
      "Train Loss tensor(50.5336, device='cuda:0')\n",
      "Val Loss tensor(45.2480, device='cuda:0')\n",
      "Train Loss tensor(49.9580, device='cuda:0')\n",
      "Val Loss tensor(45.1705, device='cuda:0')\n",
      "Train Loss tensor(49.4312, device='cuda:0')\n",
      "Val Loss tensor(45.0032, device='cuda:0')\n",
      "Train Loss tensor(49.2517, device='cuda:0')\n",
      "Val Loss tensor(44.7290, device='cuda:0')\n",
      "Train Loss tensor(48.8297, device='cuda:0')\n",
      "Val Loss tensor(45.6631, device='cuda:0')\n",
      "Train Loss tensor(48.7895, device='cuda:0')\n",
      "Val Loss tensor(44.9427, device='cuda:0')\n",
      "Train Loss tensor(48.5272, device='cuda:0')\n",
      "Val Loss tensor(44.5127, device='cuda:0')\n",
      "starting eval\n",
      "Train recons recall: tensor(0.0318, device='cuda:0')\n",
      "Train pred recall: tensor(0.0044, device='cuda:0')\n",
      "Test recons recall: tensor(0.0288, device='cuda:0')\n",
      "Test outsample recall: tensor(0.0034, device='cuda:0')\n",
      "torch.Size([10000, 9159]) torch.Size([10000, 9159]) torch.Size([10000])\n",
      "starting training\n",
      "4.1066460609436035\n",
      "Done Epoch 0\n",
      "Train Loss tensor(69.5607, device='cuda:0')\n",
      "Val Loss tensor(58.6617, device='cuda:0')\n",
      "4.099586248397827\n",
      "4.5574517250061035\n",
      "4.887660264968872\n",
      "4.9212327003479\n",
      "4.834420680999756\n",
      "4.661744594573975\n",
      "4.879855394363403\n",
      "4.914011478424072\n",
      "4.909592628479004\n",
      "4.909259080886841\n",
      "Done Epoch 10\n",
      "Train Loss tensor(66.6279, device='cuda:0')\n",
      "Val Loss tensor(59.2857, device='cuda:0')\n",
      "4.942164421081543\n",
      "4.951807498931885\n",
      "4.94920015335083\n",
      "4.9709155559539795\n",
      "4.9014668464660645\n",
      "4.901459217071533\n",
      "4.905311822891235\n",
      "4.896629333496094\n",
      "4.957174301147461\n"
     ]
    }
   ],
   "source": [
    "uniform_results = {}\n",
    "\n",
    "for s in [100, 95, 90, 80, 70]:\n",
    "    bm, br, gm, gr = compare_on_data(datapath(\"full_data.pt\"), datapath(\"full_data_test_indices.pickle\"))\n",
    "        \n",
    "    uniform_results[s] = (br, gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_results = {}\n",
    "\n",
    "for s in [95, 90, 85, 75]:\n",
    "    bm, br, gm, gr = compare_on_data(datapath(f\"train/top/top{s}_data.pt\"), datapath(f\"test/top/top{s}_test_indices.pickle\"))\n",
    "        \n",
    "    top_results[s] = (br, gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_results = {}\n",
    "\n",
    "for s in [5, 10, 15, 25]:\n",
    "    bm, br, gm, gr = compare_on_data(datapath(f\"train/middle/middle{s}_data.pt\"), datapath(f\"test/middle/middle{s}_test_indices.pickle\"))\n",
    "        \n",
    "    middle_results[s] = (br, gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGR_results = {}\n",
    "\n",
    "for s in [5, 10, 15, 25]:\n",
    "    bm, br, gm, gr = compare_on_data(datapath(f\"train/LGR/LGR{s}_data.pt\"), datapath(f\"test/LGR/LGR{s}_test_indices.pickle\"))\n",
    "        \n",
    "    LGR_results[s] = (br, gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UIS1_results = {}\n",
    "\n",
    "for s in [5, 10, 15, 25]:\n",
    "    bm, br, gm, gr = compare_on_data(datapath(f\"train/UIS1/UIS1{s}_data.pt\"), datapath(f\"test/UIS1/UIS1{s}_test_indices.pickle\"))\n",
    "        \n",
    "    UIS1_results[s] = (br, gr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
