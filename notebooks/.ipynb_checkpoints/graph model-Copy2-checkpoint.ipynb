{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nick\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# This needs to be here because by default Jupyter only adds the pwd to sys.path\n",
    "import os, sys\n",
    "if os.path.abspath('..') not in sys.path: sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pysrc.constants import datapath, N_ITEMS, N_USERS\n",
    "from pysrc.constants import cachepath, datapath, chartpath\n",
    "import torch\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {}\n",
    "test_dict = {}\n",
    "\n",
    "with open(datapath(\"train.txt\")) as file:\n",
    "    for line in file:\n",
    "        (user_id, items) = line.split(maxsplit=1)\n",
    "        train_dict[user_id] = items\n",
    "\n",
    "with open(datapath(\"test.txt\")) as file:\n",
    "    for line in file:\n",
    "        split = line.split(maxsplit=1)\n",
    "        if (len(split) > 1):\n",
    "            (user_id, items) = split\n",
    "            test_dict[user_id] = items\n",
    "        else:\n",
    "            test_dict[split[0]] = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "test = []\n",
    "for key in train_dict:\n",
    "    train.append([int(n) for n in train_dict[key].replace('\\n', '').split(' ')])\n",
    "\n",
    "for key in test_dict:\n",
    "    if len(test_dict[key]) == 0:\n",
    "        test.append([])\n",
    "    else:\n",
    "        test.append([int(n) for n in test_dict[key].replace('\\n', '').split(' ')])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9811, 0.2539, 0.5083, 0.7178, 0.3479],\n",
       "        [0.1886, 0.4130, 0.8252, 0.1679, 0.7756],\n",
       "        [0.0905, 0.2620, 0.8830, 0.2841, 0.3204],\n",
       "        [0.7884, 0.7458, 0.5503, 0.4397, 0.6396],\n",
       "        [0.7081, 0.9715, 0.6819, 0.4225, 0.4962],\n",
       "        [0.0483, 0.9642, 0.5841, 0.1368, 0.0916],\n",
       "        [0.9087, 0.3463, 0.0519, 0.7991, 0.4298],\n",
       "        [0.3684, 0.9790, 0.2057, 0.2134, 0.1930],\n",
       "        [0.3068, 0.8943, 0.5927, 0.3756, 0.6256],\n",
       "        [0.1642, 0.8763, 0.2987, 0.4170, 0.5732]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((10,5))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.8091, 2.3702, 1.8400, 3.1638, 3.2802, 1.8250, 2.5358, 1.9595, 2.7950,\n",
       "        2.3293])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def log_likelihood_loss(y, yhat):\n",
    "    return -torch.mean(torch.sum(torch.log(yhat+1e-6) * y, axis = 1))\n",
    "\n",
    "def likelihood_loss(y, yhat):\n",
    "    return -torch.mean(torch.sum(yhat * y, axis = 1))\n",
    "\n",
    "class VanillaVAE(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 latent_dim: int,\n",
    "                 hidden_dims = None,\n",
    "                 kl_weight = .2\n",
    "                 ):\n",
    "        super(VanillaVAE, self).__init__()\n",
    "        \n",
    "        self.kl_weight = kl_weight\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        modules = []\n",
    "        \n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [512, 128]\n",
    "            \n",
    "        self.hidden_dims = hidden_dims\n",
    "            \n",
    "        modules.append(nn.Linear(input_dim, hidden_dims[0]))\n",
    "        modules.append(nn.BatchNorm1d(hidden_dims[0]))\n",
    "        modules.append(nn.LeakyReLU())\n",
    "        \n",
    "        # Build Encoder\n",
    "        for i in range(len(hidden_dims)-1):\n",
    "            modules.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n",
    "            modules.append(nn.BatchNorm1d(hidden_dims[i+1]))\n",
    "            modules.append(nn.LeakyReLU())\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "        self.fc_mu = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "        self.fc_var = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "\n",
    "        # Build Decoder\n",
    "        modules = []\n",
    "\n",
    "        self.decoder_input = nn.Linear(latent_dim, hidden_dims[-1])\n",
    "\n",
    "        hidden_dims.reverse()\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n",
    "            modules.append(nn.BatchNorm1d(hidden_dims[i+1]))\n",
    "            modules.append(nn.LeakyReLU())\n",
    "\n",
    "\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "        self.final_layer = nn.Sequential(nn.Linear(hidden_dims[-1], input_dim),\n",
    "                                         nn.Sigmoid()\n",
    "                                        )\n",
    "        \n",
    "\n",
    "    def encode(self, input: Tensor):\n",
    "        \"\"\"\n",
    "        Encodes the input by passing through the encoder network\n",
    "        and returns the latent codes.\n",
    "        :param input: (Tensor) Input tensor to encoder [N x C x H x W]\n",
    "        :return: (Tensor) List of latent codes\n",
    "        \"\"\"\n",
    "        result = self.encoder(input)\n",
    "        result = torch.flatten(result, start_dim=1)\n",
    "\n",
    "        # Split the result into mu and var components\n",
    "        # of the latent Gaussian distribution\n",
    "        mu = self.fc_mu(result)\n",
    "        log_var = self.fc_var(result)\n",
    "\n",
    "        return [mu, log_var]\n",
    "\n",
    "    def decode(self, z: Tensor):\n",
    "        \"\"\"\n",
    "        Maps the given latent codes\n",
    "        onto the image space.\n",
    "        :param z: (Tensor) [B x D]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "        result = self.decoder_input(z)\n",
    "        result = result.view(-1, self.hidden_dims[0])\n",
    "        result = self.decoder(result)\n",
    "        result = self.final_layer(result)\n",
    "        result = F.normalize(result, p=1)\n",
    "        return result\n",
    "\n",
    "    def reparameterize(self, mu: Tensor, logvar: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Reparameterization trick to sample from N(mu, var) from\n",
    "        N(0,1).\n",
    "        :param mu: (Tensor) Mean of the latent Gaussian [B x D]\n",
    "        :param logvar: (Tensor) Standard deviation of the latent Gaussian [B x D]\n",
    "        :return: (Tensor) [B x D]\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "\n",
    "    def forward(self, x: Tensor, **kwargs):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        return  [F.normalize(self.decode(z), 1, dim=1), x, mu, log_var]\n",
    "\n",
    "    def loss_function(self, recons, x, mu, log_var) -> dict:\n",
    "        \"\"\"\n",
    "        Computes the VAE loss function.\n",
    "        KL(N(\\mu, \\sigma), N(0, 1)) = \\log \\frac{1}{\\sigma} + \\frac{\\sigma^2 + \\mu^2}{2} - \\frac{1}{2}\n",
    "        :param args:\n",
    "        :param kwargs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        kld_weight = self.kl_weight\n",
    "        recons_loss = log_likelihood_loss(x, recons)\n",
    "\n",
    "        kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1), dim = 0)\n",
    "\n",
    "        loss = recons_loss + kld_weight * kld_loss\n",
    "        return {'loss': loss, 'Reconstruction_Loss':recons_loss.detach(), 'KLD':-kld_loss.detach()}\n",
    "\n",
    "    def sample(self,\n",
    "               num_samples:int,\n",
    "               current_device: int, **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the latent space and return the corresponding\n",
    "        image space map.\n",
    "        :param num_samples: (Int) Number of samples\n",
    "        :param current_device: (Int) Device to run the model\n",
    "        :return: (Tensor)\n",
    "        \"\"\"\n",
    "        z = torch.randn(num_samples,\n",
    "                        self.latent_dim)\n",
    "\n",
    "        z = z.to(current_device)\n",
    "\n",
    "        samples = self.decode(z)\n",
    "        return samples\n",
    "\n",
    "    def generate(self, x: Tensor, **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Given an input image x, returns the reconstructed image\n",
    "        :param x: (Tensor) [B x C x H x W]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "\n",
    "        return self.forward(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_dim = 91599\n",
    "np.random.seed(0)\n",
    "test_ids = np.random.choice(np.array(list(train_dict.keys())).astype(int), int(.2*len(train_dict.keys())), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsify_uniform(data, p_relative = .1):\n",
    "    current_sparse = None\n",
    "    batch_size = 1000\n",
    "    X = []\n",
    "    for row in data:\n",
    "        X.append(torch.zeros(item_dim).bool())\n",
    "        for item in row:\n",
    "            if np.random.random() > p_relative:\n",
    "                X[-1][item] = 1\n",
    "        X[-1] = X[-1]\n",
    "    X = torch.stack(X)\n",
    "    return X\n",
    "    \n",
    "def sparsify_items(data, m, sigma):\n",
    "    return\n",
    "\n",
    "def sparsify_users(data, m, sigma):\n",
    "    return\n",
    "\n",
    "def list_batch_to_ohe(data):\n",
    "    return sparsify_uniform(data, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train, val, n_epochs = 100):\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "        total_loading_time = 0\n",
    "        for batch_X, batch_Y in train:\n",
    "            batch_X = batch_X.float().cuda()\n",
    "            batch_Y = batch_Y.float().cuda()\n",
    "            recons, x, mu, log_var = model.forward(batch_X)\n",
    "            train_loss = model.loss_function(recons, batch_Y, mu, log_var)['loss']\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Done Epoch {epoch}\")\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                total_train_loss = 0\n",
    "                r_train_loss = 0\n",
    "                kl_train_loss = 0\n",
    "                train_batches = 0\n",
    "                for batch_X, batch_Y in train:\n",
    "                    batch_X = batch_X.float().cuda()\n",
    "                    batch_Y = batch_Y.float().cuda()\n",
    "                    recons, x, mu, log_var = model.forward(batch_X)\n",
    "                    loss = model.loss_function(recons, batch_Y, mu, log_var)\n",
    "                    total_train_loss += loss['loss']\n",
    "                    r_train_loss += loss['Reconstruction_Loss']\n",
    "                    kl_train_loss += loss['KLD']\n",
    "                    train_batches += 1\n",
    "\n",
    "                total_train_loss /= train_batches\n",
    "                r_train_loss /= train_batches\n",
    "                kl_train_loss /= train_batches\n",
    "\n",
    "                total_loss = 0\n",
    "                r_loss = 0\n",
    "                kl_loss = 0\n",
    "                batches = 0\n",
    "                for batch_X, batch_Y in val:\n",
    "                    batch_X = batch_X.float().cuda()\n",
    "                    batch_Y = batch_Y.float().cuda()\n",
    "                    recons, x, mu, log_var = model.forward(batch_X)\n",
    "                    loss = model.loss_function(recons, batch_Y, mu, log_var)\n",
    "                    total_loss += loss['loss']\n",
    "                    r_loss += loss['Reconstruction_Loss']\n",
    "                    kl_loss += loss['KLD']\n",
    "                    batches += 1\n",
    "\n",
    "                total_loss /= batches\n",
    "                r_loss /= batches\n",
    "                kl_loss /= batches\n",
    "            print(\"Train Loss\", total_train_loss)\n",
    "            print(\"Val Loss\", total_loss)\n",
    "            \n",
    "def train_model_old(model, train, val, n_epochs = 100):\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Start Epoch {epoch}\")\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "        total_loading_time = 0\n",
    "        for batch_X, batch_Y in train:\n",
    "            batch_X = batch_X.float().cuda()\n",
    "            recons, x, mu, log_var = model.forward(batch_X)\n",
    "            train_loss = model.loss_function(recons, batch_X, mu, log_var)['loss']\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        '''\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            total_train_loss = 0\n",
    "            r_train_loss = 0\n",
    "            kl_train_loss = 0\n",
    "            train_batches = 0\n",
    "            for batch_X, batch_Y in train:\n",
    "                batch_X = batch_X.float().cuda()\n",
    "                recons, x, mu, log_var = model.forward(batch_X)\n",
    "                loss = model.loss_function(recons, batch_X, mu, log_var)\n",
    "                total_train_loss += loss['loss']\n",
    "                r_train_loss += loss['Reconstruction_Loss']\n",
    "                kl_train_loss += loss['KLD']\n",
    "                train_batches += 1\n",
    "\n",
    "            total_train_loss /= train_batches\n",
    "            r_train_loss /= train_batches\n",
    "            kl_train_loss /= train_batches\n",
    "\n",
    "            total_loss = 0\n",
    "            r_loss = 0\n",
    "            kl_loss = 0\n",
    "            batches = 0\n",
    "            for batch_X, batch_Y in val:\n",
    "                batch_X = batch_X.float().cuda()\n",
    "                recons, x, mu, log_var = model.forward(batch_X)\n",
    "                loss = model.loss_function(recons, batch_X, mu, log_var)\n",
    "                total_loss += loss['loss']\n",
    "                r_loss += loss['Reconstruction_Loss']\n",
    "                kl_loss += loss['KLD']\n",
    "                batches += 1\n",
    "\n",
    "            total_loss /= batches\n",
    "            r_loss /= batches\n",
    "            kl_loss /= batches\n",
    "        '''\n",
    "def top_k_recall(X_in, X_out, X_target, k = 20, mask_in = True):\n",
    "    if mask_in:\n",
    "        mask = X_in == False\n",
    "        X_out = X_out * mask\n",
    "    topk = torch.topk(X_out, k)\n",
    "    n = 0\n",
    "    total_recall = 0\n",
    "    for i in range(len(X_in)):\n",
    "        if int(X_target[i].sum()) == 0:\n",
    "            continue\n",
    "        selected = topk.indices[i]\n",
    "        total_recall += X_target[i][selected].sum() / X_target[i].sum()\n",
    "        n += 1\n",
    "    \n",
    "    return total_recall / n\n",
    "\n",
    "def n_recall(X_in, X_out, X_target, mask_in = True):\n",
    "    if mask_in:\n",
    "        mask = X_in == False\n",
    "        X_out = X_out * mask\n",
    "        X_target = X_target * mask\n",
    "    topk = torch.topk(X_out, int(X_target.sum(axis=1).max()), sorted=True)\n",
    "    n = 0\n",
    "    total_recall = 0\n",
    "    for i in range(len(X_in)):\n",
    "        if int(X_target[i].sum()) == 0:\n",
    "            continue\n",
    "        selected = topk.indices[i]\n",
    "        total_recall += X_target[i][selected[:int(X_target[i].sum())]].sum() / int(X_target[i].sum())\n",
    "        n += 1\n",
    "    #print(total_recall,n)\n",
    "    #print(len(X_in))\n",
    "    return total_recall / len(X_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This needs to be here because by default Jupyter only adds the pwd to sys.path\n",
    "import os, sys\n",
    "if os.path.abspath('..') not in sys.path: sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import scipy\n",
    "import pickle \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from pysrc.constants import datapath#, N_ITEMS, N_USERS\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_jaccard_sparse(csr):\n",
    "    \"\"\"Computes the Jaccard distance between the rows of `csr`,\n",
    "    smaller than the cut-off distance `epsilon`.\n",
    "    \"\"\"\n",
    "    csr = csr_matrix(csr).astype(bool).astype(int)\n",
    "\n",
    "    csr_rownnz = csr.getnnz(axis=1)\n",
    "    intrsct = csr.dot(csr.T)\n",
    "\n",
    "    nnz_i = np.repeat(csr_rownnz, intrsct.getnnz(axis=1))\n",
    "    unions = nnz_i + csr_rownnz[intrsct.indices] - intrsct.data\n",
    "    dists = intrsct.data / unions\n",
    "\n",
    "    out = csr_matrix((dists, intrsct.indices, intrsct.indptr), intrsct.shape)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_train_data = torch.load(datapath(f\"train/middle/middle5_data.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[    0,     0,     0,  ..., 52642, 52642, 52642],\n",
       "                       [    5,    15,    18,  ..., 31310, 32608, 32776]]),\n",
       "       values=tensor([True, True, True,  ..., True, True, True]),\n",
       "       size=(52643, 91599), nnz=154630, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(datapath(f\"test/middle/middle5_test_indices.pickle\"), \"rb\") as f:\n",
    "    sparse_test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nick\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\sparse\\_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    }
   ],
   "source": [
    "sim = pairwise_jaccard_sparse(sparse_train_data.to_dense())\n",
    "for i in range(sim.shape[0]):\n",
    "    sim[i,i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsify_sparse_uniform(sparse_X, p_relative = .1):\n",
    "    X = []\n",
    "    for i in range(sparse_train_data.shape[0]):\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "        X.append(torch.zeros(item_dim).bool())\n",
    "        row = sparse_X[i].coalesce().indices()[0]\n",
    "        X[-1][row] = 1\n",
    "    X = torch.stack(X)\n",
    "    return X\n",
    "    \n",
    "def sparse_to_ohe(data):\n",
    "    return sparsify_sparse_uniform(data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = sparse_train_data.bool().to_dense()\n",
    "test_df = list_batch_to_ohe(pd.Series(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52643"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mask = torch.zeros(N_USERS)\n",
    "test_mask[test_ids] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_in = dev_df[test_mask == 0]\n",
    "dev_out = test_df[test_mask == 0]\n",
    "test_in_tensor = dev_df[test_mask == 1]\n",
    "test_out_tensor = test_df[test_mask == 1]\n",
    "\n",
    "train_uids = (1-test_mask).nonzero().reshape(-1)[:int(.7*len(dev_in))]\n",
    "val_uids = (1-test_mask).nonzero().reshape(-1)[int(.7*len(dev_in)):]\n",
    "test_uids = test_mask.nonzero().reshape(-1)\n",
    "\n",
    "train_in_tensor = dev_in[:int(.7*len(dev_in))]\n",
    "val_in_tensor = dev_in[int(.7*len(dev_in)):]\n",
    "\n",
    "train_out_tensor = dev_out[:int(.7*len(dev_in))]\n",
    "val_out_tensor = dev_out[int(.7*len(dev_in)):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "def log_likelihood_loss(y, yhat):\n",
    "    return -torch.mean(torch.sum(torch.log(yhat+1e-6) * y, axis = 1))\n",
    "\n",
    "def likelihood_loss(y, yhat):\n",
    "    return -torch.mean(torch.sum(yhat * y, axis = 1))\n",
    "\n",
    "class GraphVAE(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 latent_dim: int,\n",
    "                 hidden_dims = None,\n",
    "                 kl_weight = .2,\n",
    "                 sim = None\n",
    "                 ):\n",
    "        super(GraphVAE, self).__init__()\n",
    "        \n",
    "        self.kl_weight = kl_weight\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.embeddings = torch.zeros(N_USERS, self.latent_dim).cuda()\n",
    "        \n",
    "        coo = sim.tocoo()\n",
    "        \n",
    "        values = coo.data\n",
    "        indices = np.vstack((coo.row, coo.col))\n",
    "\n",
    "        i = torch.LongTensor(indices)\n",
    "        v = torch.FloatTensor(values)\n",
    "        shape = coo.shape\n",
    "\n",
    "        self.neighbors = torch.sparse.FloatTensor(i, v, torch.Size(shape)).cuda()\n",
    "\n",
    "        \n",
    "        modules = []\n",
    "        \n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [512, 128]\n",
    "            \n",
    "        self.hidden_dims = hidden_dims\n",
    "            \n",
    "        modules.append(nn.Linear(input_dim, hidden_dims[0]))\n",
    "        modules.append(nn.BatchNorm1d(hidden_dims[0]))\n",
    "        modules.append(nn.LeakyReLU())\n",
    "        \n",
    "        # Build Encoder\n",
    "        for i in range(len(hidden_dims)-1):\n",
    "            modules.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n",
    "            modules.append(nn.BatchNorm1d(hidden_dims[i+1]))\n",
    "            modules.append(nn.LeakyReLU())\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "        self.fc_mu = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "        self.fc_var = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "\n",
    "        # Build Decoder\n",
    "        modules = []\n",
    "\n",
    "        self.decoder_input = nn.Linear(2 * latent_dim, hidden_dims[-1])\n",
    "\n",
    "        hidden_dims.reverse()\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n",
    "            modules.append(nn.BatchNorm1d(hidden_dims[i+1]))\n",
    "            modules.append(nn.LeakyReLU())\n",
    "\n",
    "\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "        self.final_layer = nn.Sequential(nn.Linear(hidden_dims[-1], input_dim),\n",
    "                                         nn.Sigmoid()\n",
    "                                        )\n",
    "        \n",
    "\n",
    "    def encode(self, input: Tensor):\n",
    "        \"\"\"\n",
    "        Encodes the input by passing through the encoder network\n",
    "        and returns the latent codes.\n",
    "        :param input: (Tensor) Input tensor to encoder [N x C x H x W]\n",
    "        :return: (Tensor) List of latent codes\n",
    "        \"\"\"\n",
    "        result = self.encoder(input)\n",
    "        result = torch.flatten(result, start_dim=1)\n",
    "        # Split the result into mu and var components\n",
    "        # of the latent Gaussian distribution\n",
    "        mu = self.fc_mu(result)\n",
    "        log_var = self.fc_var(result)\n",
    "\n",
    "        return [mu, log_var]\n",
    "\n",
    "    def decode(self, z: Tensor):\n",
    "        \"\"\"\n",
    "        Maps the given latent codes\n",
    "        onto the image space.\n",
    "        :param z: (Tensor) [B x D]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "        result = self.decoder_input(z)\n",
    "        result = result.view(-1, self.hidden_dims[0])\n",
    "        result = self.decoder(result)\n",
    "        result = self.final_layer(result)\n",
    "        result = F.normalize(result, p=1)\n",
    "        return result\n",
    "\n",
    "    def reparameterize(self, mu: Tensor, logvar: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Reparameterization trick to sample from N(mu, var) from\n",
    "        N(0,1).\n",
    "        :param mu: (Tensor) Mean of the latent Gaussian [B x D]\n",
    "        :param logvar: (Tensor) Standard deviation of the latent Gaussian [B x D]\n",
    "        :return: (Tensor) [B x D]\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "\n",
    "    def forward(self, x: Tensor, uids):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        self.embeddings[uids] = z.detach()\n",
    "        neighbors = torch.stack([self.neighbors[uid].to_dense() for uid in uids])\n",
    "        for i in range(len(uids)):\n",
    "            neighbors[i, uids[i]] = 0\n",
    "            \n",
    "        neighbors[:,test_ids] = 0\n",
    "        \n",
    "        neighbor_embeds = ((neighbors @ self.embeddings).T / (torch.sum(neighbors, axis = 1) + 1e-5)).T\n",
    "        \n",
    "        z = torch.cat([z, neighbor_embeds], axis=1)\n",
    "        \n",
    "        return  [F.normalize(self.decode(z), 1, dim=1), x, mu, log_var]\n",
    "    \n",
    "        \n",
    "    def set_embeddings(self, x, uids):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        self.embeddings[uids] = z.detach()\n",
    "\n",
    "    def loss_function(self, recons, x, mu, log_var) -> dict:\n",
    "        \"\"\"\n",
    "        Computes the VAE loss function.\n",
    "        KL(N(\\mu, \\sigma), N(0, 1)) = \\log \\frac{1}{\\sigma} + \\frac{\\sigma^2 + \\mu^2}{2} - \\frac{1}{2}\n",
    "        :param args:\n",
    "        :param kwargs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        kld_weight = self.kl_weight\n",
    "        recons_loss = log_likelihood_loss(x, recons)\n",
    "\n",
    "        kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1), dim = 0)\n",
    "\n",
    "        loss = recons_loss + kld_weight * kld_loss\n",
    "        return {'loss': loss, 'Reconstruction_Loss':recons_loss.detach(), 'KLD':-kld_loss.detach()}\n",
    "\n",
    "    def sample(self,\n",
    "               num_samples:int,\n",
    "               current_device: int, **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the latent space and return the corresponding\n",
    "        image space map.\n",
    "        :param num_samples: (Int) Number of samples\n",
    "        :param current_device: (Int) Device to run the model\n",
    "        :return: (Tensor)\n",
    "        \"\"\"\n",
    "        z = torch.randn(num_samples,\n",
    "                        self.latent_dim)\n",
    "\n",
    "        z = z.to(current_device)\n",
    "\n",
    "        samples = self.decode(z)\n",
    "        return samples\n",
    "\n",
    "    def generate(self, x: Tensor, **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Given an input image x, returns the reconstructed image\n",
    "        :param x: (Tensor) [B x C x H x W]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "\n",
    "        return self.forward(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_graph_model(model, train, val, n_epochs = 100):\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "        total_loading_time = 0\n",
    "        for batch_X, batch_Y, batch_ind in train:\n",
    "            batch_X = batch_X.float().cuda()\n",
    "            batch_Y = batch_Y.float().cuda()\n",
    "            recons, x, mu, log_var = model.forward(batch_X, batch_ind)\n",
    "            train_loss = model.loss_function(recons, batch_Y, mu, log_var)['loss']\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Done Epoch {epoch}\")\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                total_train_loss = 0\n",
    "                r_train_loss = 0\n",
    "                kl_train_loss = 0\n",
    "                train_batches = 0\n",
    "                for batch_X, batch_Y, batch_ind in train:\n",
    "                    batch_X = batch_X.float().cuda()\n",
    "                    batch_Y = batch_Y.float().cuda()\n",
    "                    recons, x, mu, log_var = model.forward(batch_X, batch_ind)\n",
    "                    loss = model.loss_function(recons, batch_Y, mu, log_var)\n",
    "                    total_train_loss += loss['loss']\n",
    "                    r_train_loss += loss['Reconstruction_Loss']\n",
    "                    kl_train_loss += loss['KLD']\n",
    "                    train_batches += 1\n",
    "\n",
    "                total_train_loss /= train_batches\n",
    "                r_train_loss /= train_batches\n",
    "                kl_train_loss /= train_batches\n",
    "\n",
    "                total_loss = 0\n",
    "                r_loss = 0\n",
    "                kl_loss = 0\n",
    "                batches = 0\n",
    "                for batch_X, batch_Y, batch_ind in val:\n",
    "                    batch_X = batch_X.float().cuda()\n",
    "                    batch_Y = batch_Y.float().cuda()\n",
    "                    recons, x, mu, log_var = model.forward(batch_X, batch_ind)\n",
    "                    loss = model.loss_function(recons, batch_Y, mu, log_var)\n",
    "                    total_loss += loss['loss']\n",
    "                    r_loss += loss['Reconstruction_Loss']\n",
    "                    kl_loss += loss['KLD']\n",
    "                    batches += 1\n",
    "\n",
    "                total_loss /= batches\n",
    "                r_loss /= batches\n",
    "                kl_loss /= batches\n",
    "                \n",
    "            print(\"Train Loss\", total_train_loss)\n",
    "            print(\"Val Loss\", total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting kl 1\n",
      "Done Epoch 0\n",
      "Train Loss tensor(172.6486, device='cuda:0')\n",
      "Val Loss tensor(123.2295, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 256\n",
    "\n",
    "sparsity = 0\n",
    "\n",
    "results = {}\n",
    "\n",
    "for kl_weight in [1]:#, .01, .02, .03, .05, .1, .2, .3, .4, .5, .6, .7, .9]:\n",
    "    print()\n",
    "    print(\"Starting kl\", kl_weight)\n",
    "    start = time.time()\n",
    "    \n",
    "    train_dataset = TensorDataset(train_in_tensor, train_in_tensor + train_out_tensor)\n",
    "    val_dataset = TensorDataset(val_in_tensor, val_in_tensor + val_out_tensor)\n",
    "    test_dataset = TensorDataset(test_in_tensor, test_in_tensor + test_out_tensor)\n",
    "    # Create a data loader from the dataset\n",
    "    # Type of sampling and batch size are specified at this step\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    lr = 1e-3\n",
    "    model = VanillaVAE(input_dim = item_dim, latent_dim = 256, hidden_dims = [512, 256], kl_weight = kl_weight).cuda()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "    train_model(model, train_dataloader, val_dataloader, n_epochs = n_epochs)\n",
    "    \n",
    "    model.eval()\n",
    "    test_ind_dataloader = DataLoader(torch.Tensor(range(len(test_in_tensor))).long(), batch_size=batch_size, shuffle=True)\n",
    "    with torch.no_grad():\n",
    "        total_n_recall_train = 0\n",
    "        total_n_train = 0\n",
    "        for batch_X, batch_Y in train_dataloader:\n",
    "            batch_out = model.forward(batch_X.float().cuda())[0].detach().cpu()\n",
    "            n_recall_batch = n_recall(batch_X, batch_out, batch_X, False)\n",
    "            total_n_recall_train += n_recall_batch * len(batch_X)\n",
    "            total_n_train += len(batch_X)\n",
    "        print(\"Train recons recall:\", total_n_recall_train / total_n_train)\n",
    "        train_recons_recall = total_n_recall_train / total_n_train\n",
    "        \n",
    "        total_n_recall_out = 0\n",
    "        total_n_out = 0\n",
    "        for batch_X, batch_Y in train_dataloader:\n",
    "            batch_out = model.forward(batch_X.float().cuda())[0].detach().cpu()\n",
    "            n_recall_batch = n_recall(batch_X, batch_out, batch_Y, True)\n",
    "            total_n_recall_out += n_recall_batch * len(batch_X)\n",
    "            total_n_out += len(batch_X)\n",
    "        print(\"Train pred recall:\", total_n_recall_out / total_n_out)\n",
    "        train_out_recall = total_n_recall_out / total_n_out\n",
    "        \n",
    "        total_n_recall_recons = 0\n",
    "        total_n_recons = 0\n",
    "        for batch_X, batch_Y in test_dataloader:\n",
    "            batch_out = model.forward(batch_X.cuda())[0].detach().cpu()\n",
    "            n_recall_batch = n_recall(batch_X, batch_out, batch_X, False)\n",
    "            total_n_recall_recons += n_recall_batch * len(batch_ind)\n",
    "            total_n_recons += len(batch_ind)\n",
    "        print(\"Test recons recall:\", total_n_recall_recons / total_n_recons)\n",
    "        test_recons_recall = total_n_recall_recons / total_n_recons\n",
    "        \n",
    "        \n",
    "        total_n_recall_out = 0\n",
    "        total_n_out = 0\n",
    "        for batch_X, batch_Y in test_dataloader:\n",
    "            batch_out = model.forward(batch_X.cuda())[0].detach().cpu()\n",
    "            n_recall_batch = n_recall(batch_X, batch_out, batch_Y, True)\n",
    "            total_n_recall_out += n_recall_batch * len(batch_ind)\n",
    "            total_n_out += len(batch_ind)\n",
    "        print(\"Test outsample recall:\", total_n_recall_out / total_n_out)\n",
    "        test_outsample_recall = total_n_recall_out / total_n_out\n",
    "    results[sparsity] = {\"train_recons\": train_recons_recall, \"test_recons\": test_recons_recall, \"test_out\": test_outsample_recall}\n",
    "    print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 256\n",
    "\n",
    "sparsity = 0\n",
    "\n",
    "results = {}\n",
    "\n",
    "for kl_weight in [1]:#, .01, .02, .03, .05, .1, .2, .3, .4, .5, .6, .7, .9]:\n",
    "    print()\n",
    "    print(\"Starting kl\", kl_weight)\n",
    "    start = time.time()\n",
    "    \n",
    "    train_dataset = TensorDataset(train_in_tensor, train_in_tensor + train_out_tensor, train_uids)\n",
    "    val_dataset = TensorDataset(val_in_tensor, val_in_tensor + val_out_tensor, val_uids)\n",
    "    test_dataset = TensorDataset(test_in_tensor, test_in_tensor + test_out_tensor, test_uids)\n",
    "    # Create a data loader from the dataset\n",
    "    # Type of sampling and batch size are specified at this step\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "    lr = 2e-3\n",
    "    graph_model = GraphVAE(input_dim = item_dim, latent_dim = 256, hidden_dims = [512, 256], kl_weight = kl_weight, sim = sim).cuda()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "    train_graph_model(graph_model, train_dataloader, val_dataloader, n_epochs = n_epochs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_Y, batch_ind in train_dataloader:\n",
    "        model.set_embeddings(batch_X, batch_ind)\n",
    "    for batch_X, batch_Y, batch_ind in val_dataloader:\n",
    "        model.set_embeddings(batch_X, batch_ind)\n",
    "    for batch_X, batch_Y, batch_ind in test_dataloader:\n",
    "        model.set_embeddings(batch_X, batch_ind)\n",
    "    \n",
    "    total_n_recall_recons = 0\n",
    "    total_n_recons = 0\n",
    "    for batch_X, batch_Y, batch_ind in val_dataloader:\n",
    "        batch_out = model.forward(batch_X.float().cuda(), batch_ind)[0].detach().cpu()\n",
    "        n_recall_batch = n_recall(batch_X, batch_out, batch_X, False)\n",
    "        total_n_recall_recons += n_recall_batch * len(batch_ind)\n",
    "        total_n_recons += len(batch_ind)\n",
    "    print(\"Val recons recall:\", total_n_recall_recons / total_n_recons)\n",
    "    test_recons_recall = total_n_recall_recons / total_n_recons\n",
    "\n",
    "\n",
    "    total_n_recall_out = 0\n",
    "    total_n_out = 0\n",
    "    for batch_X, batch_Y, batch_ind in val_dataloader:\n",
    "        batch_out = model.forward(batch_X.float().cuda(), batch_ind)[0].detach().cpu()\n",
    "        n_recall_batch = n_recall(batch_X, batch_out, batch_Y, True)\n",
    "        total_n_recall_out += n_recall_batch * len(batch_ind)\n",
    "        total_n_out += len(batch_ind)\n",
    "    print(\"Val outsample recall:\", total_n_recall_out / total_n_out)\n",
    "    test_outsample_recall = total_n_recall_out / total_n_out\n",
    "    \n",
    "    total_n_recall_recons = 0\n",
    "    total_n_recons = 0\n",
    "    for batch_X, batch_Y, batch_ind in test_dataloader:\n",
    "        batch_out = model.forward(batch_X.float().cuda(), batch_ind)[0].detach().cpu()\n",
    "        n_recall_batch = n_recall(batch_X, batch_out, batch_X, False)\n",
    "        total_n_recall_recons += n_recall_batch * len(batch_ind)\n",
    "        total_n_recons += len(batch_ind)\n",
    "    print(\"Test recons recall:\", total_n_recall_recons / total_n_recons)\n",
    "    test_recons_recall = total_n_recall_recons / total_n_recons\n",
    "\n",
    "\n",
    "    total_n_recall_out = 0\n",
    "    total_n_out = 0\n",
    "    for batch_X, batch_Y, batch_ind in test_dataloader:\n",
    "        batch_out = model.forward(batch_X.float().cuda(), batch_ind)[0].detach().cpu()\n",
    "        n_recall_batch = n_recall(batch_X, batch_out, batch_Y, True)\n",
    "        total_n_recall_out += n_recall_batch * len(batch_ind)\n",
    "        total_n_out += len(batch_ind)\n",
    "    print(\"Test outsample recall:\", total_n_recall_out / total_n_out)\n",
    "    test_outsample_recall = total_n_recall_out / total_n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_on_data(train_path, test_path):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
